
```{r, include = FALSE}
ottrpal::set_knitr_image_path()
```

# Other Laws That Can Apply to AI

While countries and jurisdictions are developing ans passing laws that specifically deal with AI, there are also existing laws around data that should be considered whenever working with AI. These broadly include regulations about intellectual property, data privacy and protection, and liability.

Keep in mind this is not an exhaustive list! This can give you a starting point of what sorts of laws and regulations you might need to consider, but you'll need to apply your own domain knowledge to determine the specifics for your organization. Always confirm with your legal council whether a particular law or regulation applies to you.

## Intellectual Property

There are multiple concerns around generative AI and intellectual property rights, especially with regards to copyright and fair use or fair dealing laws. _Copyright_ is "the exclusive legal right, given to an originator or an assignee to print, publish, perform, film, or record literary, artistic, or musical material, and to authorize others to do the same" ([Oxford Languages](https://languages.oup.com/google-dictionary-en/)). _Fair use_ and _fair dealing_ are legal doctrines that allows for limited use of copyrighted material without permission under certain circumstances. While fair use and fair dealing exceptions vary from country to country, they broadly allow for nonprofit, educational, commentary or criticism, satire, and highly creative works to sample copyrighted material. 

In order for generative AI models to work, they must be trained on vast amounts of data. This might include images, in the case of image generators like DALL-E, Stable Diffusion, and Midjourney. It might also include human writing and speech, in the case of LLMs like ChatGPT and Bard. Information about the training data sets for these tools is limited, but they likely include text and images scraped from the internet. 

:::{.example}
There is concern that the text and images gathered for training data included copyrighted and trademarked books, articles, photographs, and artwork. In fact, the CEO of Midjourney confirmed that copyrighted images were included in the Midjourney training data without the consent of the artists, and there was no way for artists to opt out of having their work included. A group of authors have also recently sued OpenAI, the company behind ChatGPT, for copyright infringement because their published works were included in the GPT training data. Additionally, some artists have sued AI companies like the company behind Stable Diffusion because the generative AI tools are creating images that are too similar to their existing, protected artwork.
:::

There is also ongoing debate as to whether AI-generated images and text can be copyrighted. While many current copyright laws do not protect works created by machines, how these laws might apply to work that is a collaboration between humans and machine (such as art that includes some AI-generated content) is an area of active discussion.

## Information Security

Initial concerns around AI and information security focused on bad actors using LLMs to generate malicious code that could be used for cyberattacks. While commercially available chatbots have guardrails in place that are meant to prevent them from being used to create such code, users were able to come up with workarounds to bypass these safety checks.

More recently people have begun to worry about AI systems themselves being hacked. 

:::{.example}
OpenAI security breach
:::

## Data Privacy

SOMETHING ABOUT PERSONAL DATA

Data privacy is especially important to consider when working in fields like healthcare, biomedical research, and education, where personally identifiable data and personal health information is under special protections. Special consideration should also be taken when dealing with biometric data, or data involving human characteristics gathered from physical or behavioral traits that can be used to identify a single person. This might include things like fingerprints, palm prints, iris scans, facial scans, and voice recognition. DNA can also be considered biometric data when used for forensics.


## Liability

As AI systems become more and more common in everyday life, it is inevitable that some of these systems will fail at some point. Who is liable when AI fails, especially when it fails in a catastrophic manner?

The issue of whose fault it is when an AI system fails (and thus who is responsible for the damage) depends greatly on _how_ and _why_ it failed. Blame might lie with the user (if the AI was not being used according to instructions, or if limitations were known but ignored), the software developer (if the AI product was distributed before being tested thoroughly or before the algorithm was properly tuned), or the designer or manufacturer (if the AI design or production was inherently flawed).

:::{.example}
Tesla self-driving cars
:::

## Who can tell you about your particular legal concerns

Talk to legal council

Talk to a Data Governance specialist

# VIDEO Existing Laws That Apply to AI
