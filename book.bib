@Manual{rmarkdown2021,
  title = {rmarkdown: Dynamic Documents for R},
  author = {JJ Allaire and Yihui Xie and Jonathan McPherson and Javier Luraschi and Kevin Ushey and Aron Atkins and Hadley Wickham and Joe Cheng and Winston Chang and Richard Iannone},
  year = {2021},
  note = {R package version 2.10},
  url = {https://github.com/rstudio/rmarkdown},
}

@Book{Xie2018,
  title = {R Markdown: The Definitive Guide},
  author = {Yihui Xie and J.J. Allaire and Garrett Grolemund},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2018},
  note = {ISBN 9781138359338},
  url = {https://bookdown.org/yihui/rmarkdown},
}

@Book{Xie2020,
  title = {R Markdown Cookbook},
  author = {Yihui Xie and Christophe Dervieux and Emily Riederer},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2020},
  note = {ISBN 9780367563837},
  url = {https://bookdown.org/yihui/rmarkdown-cookbook},
}

@ARTICLE{Mattson2014,
  	AUTHOR={Mattson, Mark P.},   
	 TITLE={Superior pattern processing is the essence of the evolved human brain},      
	JOURNAL={Frontiers in Neuroscience},      
	VOLUME={8},           
	YEAR={2014},      
	  URL={https://www.frontiersin.org/articles/10.3389/fnins.2014.00265},       
	DOI={10.3389/fnins.2014.00265},      
	ISSN={1662-453X},   
	ABSTRACT={Humans have long pondered the nature of their mind/brain and, particularly why its capacities for reasoning, communication and abstract thought are far superior to other species, including closely related anthropoids. This article considers superior pattern processing (SPP) as the fundamental basis of most, if not all, unique features of the human brain including intelligence, language, imagination, invention, and the belief in imaginary entities such as ghosts and gods. SPP involves the electrochemical, neuronal network-based, encoding, integration, and transfer to other individuals of perceived or mentally-fabricated patterns. During human evolution, pattern processing capabilities became increasingly sophisticated as the result of expansion of the cerebral cortex, particularly the prefrontal cortex and regions involved in processing of images. Specific patterns, real or imagined, are reinforced by emotional experiences, indoctrination and even psychedelic drugs. Impaired or dysregulated SPP is fundamental to cognitive and psychiatric disorders. A broader understanding of SPP mechanisms, and their roles in normal and abnormal function of the human brain, may enable the development of interventions that reduce irrational decisions and destructive behaviors.}
}

@article{belenguer_ai_2022,
	title = {{AI} bias: exploring discriminatory algorithmic decision-making models and the application of possible machine-centric solutions adapted from the pharmaceutical industry},
	volume = {2},
	issn = {2730-5953},
	shorttitle = {{AI} bias},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8830968/},
	doi = {10.1007/s43681-022-00138-8},
	abstract = {A new and unorthodox approach to deal with discriminatory bias in Artificial Intelligence is needed. As it is explored in detail, the current literature is a dichotomy with studies originating from the contrasting fields of study of either philosophy and sociology or data science and programming. It is suggested that there is a need instead for an integration of both academic approaches, and needs to be machine-centric rather than human-centric applied with a deep understanding of societal and individual prejudices. This article is a novel approach developed into a framework of action: a bias impact assessment to raise awareness of bias and why, a clear set of methodologies as shown in a table comparing with the four stages of pharmaceutical trials, and a summary flowchart. Finally, this study concludes the need for a transnational independent body with enough power to guarantee the implementation of those solutions.},
	number = {4},
	urldate = {2023-05-02},
	journal = {Ai and Ethics},
	author = {Belenguer, Lorenzo},
	year = {2022},
	pmid = {35194591},
	pmcid = {PMC8830968},
	pages = {771--787}
}

@misc{AI_paternalism,
	title = {Artificial intelligence is infiltrating health care. {We} shouldn’t let it make all the decisions.},
	url = {https://www.technologyreview.com/2023/04/21/1071921/ai-is-infiltrating-health-care-we-shouldnt-let-it-make-decisions/},
	abstract = {AI paternalism could put patient autonomy at risk—if we let it.},
	language = {en},
	author = {Jessica Hamzelou},
	urldate = {2023-05-08},
	journal = {MIT Technology Review},
}


@misc{kowaleski_can_2019,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Can {Ethics} be {Taught}? {Evidence} from {Securities} {Exams} and {Investment} {Adviser} {Misconduct}},
	shorttitle = {Can {Ethics} be {Taught}?},
	url = {https://papers.ssrn.com/abstract=3457588},
	doi = {10.2139/ssrn.3457588},
	abstract = {We study the consequences of a 2010 change in the investment adviser qualification exam that reallocated coverage from the rules and ethics section to the technical material section. Comparing advisers with the same employer in the same location and year, we find those passing the exam with more rules and ethics coverage are one-fourth less likely to commit misconduct. The exam change appears to affect advisers’ perception of acceptable conduct, and not just their awareness of specific rules or selection into the qualification. Those passing the rules and ethics-focused exam are more likely to depart employers experiencing scandals. Such departures also predict future scandals. Our paper offers the first archival evidence on how rules and ethics training affects conduct and labor market activity in the financial sector.},
	language = {en},
	urldate = {2023-12-12},
	author = {Kowaleski, Zachary T. and Sutherland, Andrew and Vetter, Felix},
	month = sep,
	year = {2019},
	keywords = {compliance training, ethics, ethics training, financial misconduct, financial regulation, fraud, investment advisers, labor economics},
}

@article{giorgini_researcher_2015,
	title = {Researcher {Perceptions} of {Ethical} {Guidelines} and {Codes} of {Conduct}},
	volume = {22},
	issn = {0898-9621},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313573/},
	doi = {10.1080/08989621.2014.955607},
	abstract = {Ethical codes of conduct exist in almost every profession. Field-specific codes of conduct have been around for decades, each articulating specific ethical and professional guidelines. However, there has been little empirical research on researchers’ perceptions of these codes of conduct. In the present study, we interviewed faculty members in six research disciplines and identified five themes bearing on the circumstances under which they use ethical guidelines and the underlying reasons for not adhering to such guidelines. We then identify problems with the manner in which codes of conduct in academia are constructed and offer solutions for overcoming these problems.},
	number = {3},
	urldate = {2023-12-12},
	journal = {Accountability in research},
	author = {Giorgini, Vincent and Mecca, Jensen T. and Gibson, Carter and Medeiros, Kelsey and Mumford, Michael D. and Connelly, Shane and Devenport, Lynn D.},
	year = {2015},
	pmid = {25635845},
	pmcid = {PMC4313573},
	pages = {123--138},
}


@article{pethig_biased_2023,
	title = {Biased {Humans}, ({Un}){Biased} {Algorithms}?},
	volume = {183},
	issn = {1573-0697},
	url = {https://doi.org/10.1007/s10551-022-05071-8},
	doi = {10.1007/s10551-022-05071-8},
	abstract = {Previous research has shown that algorithmic decisions can reflect gender bias. The increasingly widespread utilization of algorithms in critical decision-making domains (e.g., healthcare or hiring) can thus lead to broad and structural disadvantages for women. However, women often experience bias and discrimination through human decisions and may turn to algorithms in the hope of receiving neutral and objective evaluations. Across three studies (N = 1107), we examine whether women’s receptivity to algorithms is affected by situations in which they believe that their gender identity might disadvantage them in an evaluation process. In Study 1, we establish, in an incentive-compatible online setting, that unemployed women are more likely to choose to have their employment chances evaluated by an algorithm if the alternative is an evaluation by a man rather than a woman. Study 2 generalizes this effect by placing it in a hypothetical hiring context, and Study 3 proposes that relative algorithmic objectivity, i.e., the perceived objectivity of an algorithmic evaluator over and against a human evaluator, is a driver of women’s preferences for evaluations by algorithms as opposed to men. Our work sheds light on how women make sense of algorithms in stereotype-relevant domains and exemplifies the need to provide education for those at risk of being adversely affected by algorithmic decisions. Our results have implications for the ethical management of algorithms in evaluation settings. We advocate for improving algorithmic literacy so that evaluators and evaluatees (e.g., hiring managers and job applicants) can acquire the abilities required to reflect critically on algorithmic decisions.},
	language = {en},
	number = {3},
	urldate = {2023-12-13},
	journal = {Journal of Business Ethics},
	author = {Pethig, Florian and Kroenung, Julia},
	month = mar,
	year = {2023},
	keywords = {Algorithms, Gender bias, Objectivity, Stigma},
	pages = {637--652},
}


@article{dastin_insight_2018,
	chapter = {World},
	title = {Insight - {Amazon} scraps secret {AI} recruiting tool that showed bias against women},
	url = {https://www.reuters.com/article/idUSKCN1MK0AG/},
	abstract = {Amazon.com Inc's \&lt;AMZN.O\&gt; machine-learning specialists uncovered a big problem: their new recruiting engine did not like women.},
	language = {en-US},
	urldate = {2023-12-13},
	journal = {Reuters},
	author = {Dastin, Jeffrey},
	month = oct,
	year = {2018},

}


@article{gichoya_ai_2022,
	title = {{AI} recognition of patient race in medical imaging: a modelling study},
	volume = {4},
	issn = {2589-7500},
	shorttitle = {{AI} recognition of patient race in medical imaging},
	url = {https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00063-2/fulltext},
	doi = {10.1016/S2589-7500(22)00063-2},
	language = {English},
	number = {6},
	urldate = {2023-12-13},
	journal = {The Lancet Digital Health},
	author = {Gichoya, Judy Wawira and Banerjee, Imon and Bhimireddy, Ananth Reddy and Burns, John L. and Celi, Leo Anthony and Chen, Li-Ching and Correa, Ramon and Dullerud, Natalie and Ghassemi, Marzyeh and Huang, Shih-Cheng and Kuo, Po-Chih and Lungren, Matthew P. and Palmer, Lyle J. and Price, Brandon J. and Purkayastha, Saptarshi and Pyrros, Ayis T. and Oakden-Rayner, Lauren and Okechukwu, Chima and Seyyed-Kalantari, Laleh and Trivedi, Hari and Wang, Ryan and Zaiman, Zachary and Zhang, Haoran},
	month = jun,
	year = {2022},
	pmid = {35568690},
	note = {Publisher: Elsevier},
	pages = {e406--e414},


