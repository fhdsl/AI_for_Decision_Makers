


# Ground Rules for AI

The rapidly changing AI landscape has brought unexpected ethical challenges. To promote benefit over harm, we suggest following these AI use and development guidelines:

1. **Recognize guidelines**. Today, there are some guidelines for ethical use. More will be developed. It is advised that you stay up-to-date on industry-specific guidelines.

1. **Consider consequences**. Think about possible downstream unintended consequences for using AI. This could be in the context of creating content or developing new AI tools. 

1. **Acknowledge shortcomings**. AI is not perfect. It makes mistakes, is not necessarily superior to humans, and should be used as intended and trained. It is also only as up-to-date as its training data. While humans are very good at generalizing knowledge for different contexts, AI systems can sometimes struggle with this. Human oversight is needed for important and consequential uses.

1. **Understand bias**. Realize that AI often perpetuates bias. AI is created using data generated by humans, and that data can be biased. It is important to use inclusive datasets and seek expert advice.

1. **Promote access**. Promote equitable access to AI. Differences in access could worsen existing disparities, or create new ones. 

1. **Think securely**. AI poses security and privacy threats. AI needs to be used and developed carefully with these aspects in mind. Do not use proprietary or private information as prompts for consumer AI tools unless it was specifically designed for private data.

1. **Understand costs**. AI could exacerbate global climate change and human welfare disparities. Developers should be considerate about their computation needs and not use larger than necessary datasets. Workers who label and curate datasets should be compensated appropriately.

1. **Be transparent**. Users should be transparent about their use of AI tools. It makes it easier to locate the source of issues. It also helps to uplift human contributions to work and art.

1. **Credit sources**. When developing tools, be transparent about what data you used to create your AI systems. Be careful not to use work or data from individuals who did not consent to it being used in such ways.

1. **Work thoughtfully**. Ramp up AI projects gradually to identify unexpected behaviors or impacts before full deployment. Starting slowly enables recognition and resolution of issues.

1. **Acknowledge complexity**. Recognize that if AI systems use overly complex models, it can be difficult to trace how decisions are made using them.

1. **Diversify usage**. Check the consistency of results using multiple AI tools and timepoints, where possible.

1. **Keep learning**. Educate yourself and others. To comply with ethical standards, users must be educated about best use practices. If you help set standards for an institution or group, it strongly advised that you carefully consider how to educate individuals about those standards of use.

To learn more about how to responsibly use and develop AI, check out the following minicourse about Avoiding AI harm.

<!-- # VIDEO Knowing the Ground Rules {.unlisted .unnumbered} -->

<br>
<div class = disclaimer>
**Disclaimer:** The thoughts and ideas presented in this course are not to be substituted for legal or ethical advice and are only meant to give you a starting point for gathering information about AI policy and regulations to consider.
</div>
