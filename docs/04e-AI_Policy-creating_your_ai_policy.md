

# Considerations for creating an AI Policy

AI tools are already changing how we work, and they will continue to do so for years. Over the next few years, we're likely going to see AI used in ways we've never imagined and aren't anticipating. People are going to use AI one way or another. As a decision maker, you want to support them so they can be successful and not fall into traps. How can you guide your organization to adopt AI in a way that's not unethical, illegal, or wrong?

## An AI policy alone is probably not enough

Building in an AI support system is also important. This might include the infrastructure to handle AI, guidelines on AI best practices, training materials, and other things that will make it possible for people to adopt AI in the safest and most ethical ways.

It's easy to write in a policy "Don't use LLMs", but in practice that might be difficult to enforce. Instead, you might want to adopt a policy that allows LLM use in specific circumstances that allow people to use them in ways that makes it difficult to get into trouble, and then create a support system around that.

For example, many AIs have a user agreement. Two possible types of user agreements are commercial agreements (which is what individual users generally have) and enterprise agreements (which is what organizations and institutions might have). The terms and conditions of enterprise agreements tend to be more stable over time and can be negotiated with legally binding terms like any contract. If your organization signs an enterprise agreement, you might be able to stipulate terms like your data not being used as part of the AI's training data.

If an employee uses an AI system as a single consumer with upgraded IT license agreement, they may have fewer legal protections than an employee operating under an enterprise agreement. Consumer agreements can change unexpectedly, which means you could be operating under a whole new set of circumstances month to month. Additionally, consumers do not have the same sort of negotiating power with consumer agreements, so they cannot stipulate terms about what happens to their data.

Thinking about your AI policy as just the beginning can be a way to protect your employees, your organization, and the people you serve.

## Get lots of voices weighing in from the beginning

You probably need a lot of different people to weigh in to get even close to what you want in terms of a good AI policy. 

AI systems are being integrated into every aspect of the work environment. Limiting policy creation to just the Chief Data Officer's office or the IT department or the legal department might make things faster, but the trade-off is that you are likely only covering a fraction of what you need. At minimum, most organizations probably need representatives from legal, compliance and governance, IT , offices of diversity, equity, inclusion, ethical review, and training. Creating a meaningful policy and getting the necessary supports put in place is easier when you have people with varied and broad expertise creating the policy from the beginning.

## Consider how to keep your guidance agile

The speed at which AI technology is changing is fast enough that creating useful guidelines around its use is difficult. An AI policy requires you to get a diverse set of opinions together and make it cohesive and coherent, and that takes time. The last thing you want to do is create a policy that no longer applies in 3 months when AI systems have changed again.

So how you systematize the process of doing creating your policy so that you can easily update it when necessary? One possible way is to think of your AI Policy as an ongoing living thing as opposed to a one time effort. This might include creating both an AI Policy and an AI Best Practices document. 

In a situation like this, the policy evolves more slowly and the best practices evolves more quickly. For example, the policy document might say something like "you should use infrastructure that matches current best practices." This allows you to create a policy that is still useful over time as your organization learns what AI practices and infrastructure is best for it.

The best practices can change more rapidly with more frequent updates, leaving the policy somewhat stable. This still requires you to communicate frequently with your employees on the state of the best practices for AI use. However, the best practices can be tailored to fit specific departments and change as those departments need it to do so. This also allows an organization to communicate to specific departments and employees who might be affected by an update to their best practices guidelines.

You should also consider whether asynchronous collaboration versus synchronous collaboration is right for your organization when creating and updating your policy and best practices documents. With an asynchronous approach, people write their individual sections of a document by a deadline, after which the full policy is polished and edited. With a synchronous approach, an organization might convene a set of meetings with experts over a length or time to work on the document together. There are benefits and drawbacks to both approaches, and you will know which best fits your organization's needs.

## Adopting good practices now can benefit your organization

When technological shifts happen, there's always a period of explosive growth where the technology and what's possible changes incredibly quickly. We're in that stage right now with AI. Really surprising things that we never anticipated will happen, and they'll happen pretty regularly. We'll have to adapt.

With the rapid changes also comes a fear about what this new technology means for the world and our current way of working. The new world is going be different and things will change in some ways, both big and small. Some things will get a little better and some things will go wrong. However, adopting this new technology at the right time can really change a lot of things for you and also give you the opportunity to guide and direct your future and the future of your organization. It's a bit like catching the tail of a rocket ship that just being launched, but catching it in a way that doesn't like burn you to a crisp.

Thirty or so years ago, we had a similar technological shift with the advent of the Internet. At the time, using the Internet for common, everyday tasks was a big deal, and there was fear about how it would change how we work. Now, we have accepted the Internet as a way of life and it's a normal experience to look things up on Google or shop on the internet. In 30 years, AI systems will be the same.

# VIDEO Title!
