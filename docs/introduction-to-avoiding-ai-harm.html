<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 16 Introduction to Avoiding AI Harm | How AI Works</title>
  <meta name="description" content="Description about Course/Book." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 16 Introduction to Avoiding AI Harm | How AI Works" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Description about Course/Book." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 16 Introduction to Avoiding AI Harm | How AI Works" />
  
  <meta name="twitter:description" content="Description about Course/Book." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/dasl_favicon.ico" type="image/x-icon" />
<link rel="prev" href="video-knowing-the-ground-rules.html"/>
<link rel="next" href="consent-and-ai.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-YLGCFXEHPV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-YLGCFXEHPV');
  </script>





<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="assets/style.css" type="text/css" />
<link rel="stylesheet" href="assets/style_custom.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<a href="https://hutchdatascience.org/" target="_blank"><img src="assets/big-dasl-stacked.png" style="width: 80%; padding-left: 34px; padding-top: 8px;"</a>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Course</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#specialization-sections"><i class="fa fa-check"></i><b>0.1</b> Specialization Sections</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#available-course-formats"><i class="fa fa-check"></i><b>0.2</b> Available course formats</a></li>
</ul></li>
<li class="part"><span><b>Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="video-summary-of-this-course.html"><a href="video-summary-of-this-course.html"><i class="fa fa-check"></i><b>1</b> VIDEO Summary of This Course</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#motivation"><i class="fa fa-check"></i><b>2.1</b> Motivation</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#target-audience"><i class="fa fa-check"></i><b>2.2</b> Target Audience</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#curriculum"><i class="fa fa-check"></i><b>2.3</b> Curriculum</a></li>
</ul></li>
<li class="part"><span><b>AI Possibilities</b></span></li>
<li class="chapter" data-level="3" data-path="introduction-to-ai-possibilities.html"><a href="introduction-to-ai-possibilities.html"><i class="fa fa-check"></i><b>3</b> Introduction to AI Possibilities</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction-to-ai-possibilities.html"><a href="introduction-to-ai-possibilities.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-to-ai-possibilities.html"><a href="introduction-to-ai-possibilities.html#motivation-1"><i class="fa fa-check"></i><b>3.1.1</b> Motivation</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction-to-ai-possibilities.html"><a href="introduction-to-ai-possibilities.html#target-audience-1"><i class="fa fa-check"></i><b>3.1.2</b> Target Audience</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction-to-ai-possibilities.html"><a href="introduction-to-ai-possibilities.html#curriculum-summary"><i class="fa fa-check"></i><b>3.1.3</b> Curriculum Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="video-what-is-ai.html"><a href="video-what-is-ai.html"><i class="fa fa-check"></i><b>4</b> VIDEO What Is AI</a></li>
<li class="chapter" data-level="5" data-path="what-is-ai.html"><a href="what-is-ai.html"><i class="fa fa-check"></i><b>5</b> What Is AI</a>
<ul>
<li class="chapter" data-level="5.1" data-path="what-is-ai.html"><a href="what-is-ai.html#our-ai-definition"><i class="fa fa-check"></i><b>5.1</b> Our AI Definition</a></li>
<li class="chapter" data-level="5.2" data-path="what-is-ai.html"><a href="what-is-ai.html#ai-in-practice"><i class="fa fa-check"></i><b>5.2</b> AI In Practice</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="what-is-ai.html"><a href="what-is-ai.html#amazon-recommendations"><i class="fa fa-check"></i><b>5.2.1</b> Amazon Recommendations</a></li>
<li class="chapter" data-level="5.2.2" data-path="what-is-ai.html"><a href="what-is-ai.html#financial-forecasting"><i class="fa fa-check"></i><b>5.2.2</b> Financial Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="what-is-ai.html"><a href="what-is-ai.html#what-is-and-is-not-ai"><i class="fa fa-check"></i><b>5.3</b> What Is and Is Not AI</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="what-is-ai.html"><a href="what-is-ai.html#smartphones"><i class="fa fa-check"></i><b>5.3.1</b> Smartphones</a></li>
<li class="chapter" data-level="5.3.2" data-path="what-is-ai.html"><a href="what-is-ai.html#calculators"><i class="fa fa-check"></i><b>5.3.2</b> Calculators</a></li>
<li class="chapter" data-level="5.3.3" data-path="what-is-ai.html"><a href="what-is-ai.html#computer-programs"><i class="fa fa-check"></i><b>5.3.3</b> Computer Programs</a></li>
<li class="chapter" data-level="5.3.4" data-path="what-is-ai.html"><a href="what-is-ai.html#discussion-is-it-ai"><i class="fa fa-check"></i><b>5.3.4</b> DISCUSSION Is It AI</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="video-how-ai-works.html"><a href="video-how-ai-works.html"><i class="fa fa-check"></i><b>6</b> VIDEO How AI Works</a></li>
<li class="chapter" data-level="7" data-path="how-ai-works.html"><a href="how-ai-works.html"><i class="fa fa-check"></i><b>7</b> How AI Works</a>
<ul>
<li class="chapter" data-level="7.1" data-path="how-ai-works.html"><a href="how-ai-works.html#machines-can-learn-like-us"><i class="fa fa-check"></i><b>7.1</b> Machines Can Learn Like Us</a></li>
<li class="chapter" data-level="7.2" data-path="how-ai-works.html"><a href="how-ai-works.html#the-data-explosion"><i class="fa fa-check"></i><b>7.2</b> The Data Explosion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="video-different-types-of-ai.html"><a href="video-different-types-of-ai.html"><i class="fa fa-check"></i><b>8</b> VIDEO Different Types of AI</a></li>
<li class="chapter" data-level="9" data-path="types-of-ai.html"><a href="types-of-ai.html"><i class="fa fa-check"></i><b>9</b> Types of AI</a></li>
<li class="chapter" data-level="10" data-path="video-real-life-possibilities.html"><a href="video-real-life-possibilities.html"><i class="fa fa-check"></i><b>10</b> VIDEO Real Life Possibilities</a></li>
<li class="chapter" data-level="11" data-path="what-is-possible.html"><a href="what-is-possible.html"><i class="fa fa-check"></i><b>11</b> What Is Possible</a></li>
<li class="chapter" data-level="12" data-path="video-what-is-possible.html"><a href="video-what-is-possible.html"><i class="fa fa-check"></i><b>12</b> VIDEO What Is Possible</a></li>
<li class="chapter" data-level="13" data-path="video-what-is-not-possible.html"><a href="video-what-is-not-possible.html"><i class="fa fa-check"></i><b>13</b> VIDEO What Is NOT Possible</a></li>
<li class="chapter" data-level="14" data-path="ground-rules-for-ai.html"><a href="ground-rules-for-ai.html"><i class="fa fa-check"></i><b>14</b> Ground Rules for AI</a></li>
<li class="chapter" data-level="15" data-path="video-knowing-the-ground-rules.html"><a href="video-knowing-the-ground-rules.html"><i class="fa fa-check"></i><b>15</b> VIDEO Knowing the Ground Rules</a></li>
<li class="part"><span><b>Avoiding AI Harm</b></span></li>
<li class="chapter" data-level="16" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html"><i class="fa fa-check"></i><b>16</b> Introduction to Avoiding AI Harm</a>
<ul>
<li class="chapter" data-level="16.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#learning-objectives"><i class="fa fa-check"></i><b>16.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="16.2" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#major-concerns"><i class="fa fa-check"></i><b>16.2</b> Major concerns</a></li>
<li class="chapter" data-level="16.3" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#replacing-humans"><i class="fa fa-check"></i><b>16.3</b> Replacing Humans</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-for-supporting-human-contributions"><i class="fa fa-check"></i><b>16.3.1</b> Tips for supporting human contributions</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#inappropriate-uses"><i class="fa fa-check"></i><b>16.4</b> Inappropriate Uses</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-for-avoiding-inappropriate-uses"><i class="fa fa-check"></i><b>16.4.1</b> Tips for avoiding inappropriate uses</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#bias"><i class="fa fa-check"></i><b>16.5</b> Bias</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-for-avoiding-bias"><i class="fa fa-check"></i><b>16.5.1</b> Tips for avoiding bias</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#misinformation-and-faulty-responses"><i class="fa fa-check"></i><b>16.6</b> Misinformation and Faulty Responses</a>
<ul>
<li class="chapter" data-level="16.6.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-for-reducing-misinformation-faulty-responses"><i class="fa fa-check"></i><b>16.6.1</b> Tips for reducing misinformation &amp; faulty responses</a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#lack-of-interpretability"><i class="fa fa-check"></i><b>16.7</b> Lack of Interpretability</a>
<ul>
<li class="chapter" data-level="16.7.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-for-avoiding-a-lack-of-interpretability"><i class="fa fa-check"></i><b>16.7.1</b> Tips for avoiding a lack of interpretability</a></li>
</ul></li>
<li class="chapter" data-level="16.8" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#security-and-privacy-issues"><i class="fa fa-check"></i><b>16.8</b> Security and Privacy issues</a>
<ul>
<li class="chapter" data-level="16.8.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-for-reducing-security-and-privacy-issues"><i class="fa fa-check"></i><b>16.8.1</b> Tips for reducing security and privacy issues</a></li>
</ul></li>
<li class="chapter" data-level="16.9" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#violating-copyright"><i class="fa fa-check"></i><b>16.9</b> Violating Copyright</a>
<ul>
<li class="chapter" data-level="16.9.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-for-avoiding-copyright-violations"><i class="fa fa-check"></i><b>16.9.1</b> Tips for avoiding copyright violations</a></li>
</ul></li>
<li class="chapter" data-level="16.10" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#harmful-or-toxic-responses"><i class="fa fa-check"></i><b>16.10</b> Harmful or Toxic Responses</a>
<ul>
<li class="chapter" data-level="16.10.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-for-avoiding-the-creation-of-harmful-content"><i class="fa fa-check"></i><b>16.10.1</b> Tips for avoiding the creation of harmful content</a></li>
</ul></li>
<li class="chapter" data-level="16.11" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#same-tool-over-reliance"><i class="fa fa-check"></i><b>16.11</b> Same Tool Over-reliance</a>
<ul>
<li class="chapter" data-level="16.11.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-for-avoiding-over-reliance"><i class="fa fa-check"></i><b>16.11.1</b> Tips for avoiding over-reliance</a></li>
</ul></li>
<li class="chapter" data-level="16.12" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#lack-of-education"><i class="fa fa-check"></i><b>16.12</b> Lack of education</a>
<ul>
<li class="chapter" data-level="16.12.1" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#tips-to-avoid-a-lack-of-education"><i class="fa fa-check"></i><b>16.12.1</b> Tips to avoid a lack of education</a></li>
</ul></li>
<li class="chapter" data-level="16.13" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#summary"><i class="fa fa-check"></i><b>16.13</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="consent-and-ai.html"><a href="consent-and-ai.html"><i class="fa fa-check"></i><b>17</b> Consent and AI</a></li>
<li class="chapter" data-level="18" data-path="idare-and-ai.html"><a href="idare-and-ai.html"><i class="fa fa-check"></i><b>18</b> IDARE and AI</a>
<ul>
<li class="chapter" data-level="18.1" data-path="idare-and-ai.html"><a href="idare-and-ai.html#ai-is-biased"><i class="fa fa-check"></i><b>18.1</b> AI is biased</a></li>
<li class="chapter" data-level="18.2" data-path="idare-and-ai.html"><a href="idare-and-ai.html#examples-of-ai-bias"><i class="fa fa-check"></i><b>18.2</b> Examples of AI Bias</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="idare-and-ai.html"><a href="idare-and-ai.html#amazons-resume-system-was-biased-against-women"><i class="fa fa-check"></i><b>18.2.1</b> Amazon’s resume system was biased against women</a></li>
<li class="chapter" data-level="18.2.2" data-path="idare-and-ai.html"><a href="idare-and-ai.html#x-ray-studies-show-ai-surprises"><i class="fa fa-check"></i><b>18.2.2</b> X-ray studies show AI surprises</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="idare-and-ai.html"><a href="idare-and-ai.html#mitigation"><i class="fa fa-check"></i><b>18.3</b> Mitigation</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="be-extremely-careful-using-ai-for-decisions.html"><a href="be-extremely-careful-using-ai-for-decisions.html"><i class="fa fa-check"></i><b>19</b> Be extremely careful using AI for decisions</a>
<ul>
<li class="chapter" data-level="19.1" data-path="be-extremely-careful-using-ai-for-decisions.html"><a href="be-extremely-careful-using-ai-for-decisions.html#more-inclusive-teams-means-better-models"><i class="fa fa-check"></i><b>19.1</b> More inclusive teams means better models</a></li>
</ul></li>
<li class="part"><span><b>Establishing AI Infrastructure</b></span></li>
<li class="chapter" data-level="20" data-path="introduction-to-establishing-ai-infrastructure.html"><a href="introduction-to-establishing-ai-infrastructure.html"><i class="fa fa-check"></i><b>20</b> Introduction to Establishing AI Infrastructure</a>
<ul>
<li class="chapter" data-level="20.1" data-path="introduction-to-establishing-ai-infrastructure.html"><a href="introduction-to-establishing-ai-infrastructure.html#motivation-2"><i class="fa fa-check"></i><b>20.1</b> Motivation</a></li>
<li class="chapter" data-level="20.2" data-path="introduction-to-establishing-ai-infrastructure.html"><a href="introduction-to-establishing-ai-infrastructure.html#target-audience-2"><i class="fa fa-check"></i><b>20.2</b> Target Audience</a></li>
<li class="chapter" data-level="20.3" data-path="introduction-to-establishing-ai-infrastructure.html"><a href="introduction-to-establishing-ai-infrastructure.html#curriculum-1"><i class="fa fa-check"></i><b>20.3</b> Curriculum</a></li>
</ul></li>
<li class="part"><span><b>AI Policy</b></span></li>
<li class="chapter" data-level="21" data-path="introduction-to-ai-policy.html"><a href="introduction-to-ai-policy.html"><i class="fa fa-check"></i><b>21</b> Introduction to AI Policy</a>
<ul>
<li class="chapter" data-level="21.1" data-path="introduction-to-ai-policy.html"><a href="introduction-to-ai-policy.html#motivation-3"><i class="fa fa-check"></i><b>21.1</b> Motivation</a></li>
<li class="chapter" data-level="21.2" data-path="introduction-to-ai-policy.html"><a href="introduction-to-ai-policy.html#target-audience-3"><i class="fa fa-check"></i><b>21.2</b> Target Audience</a></li>
<li class="chapter" data-level="21.3" data-path="introduction-to-ai-policy.html"><a href="introduction-to-ai-policy.html#curriculum-2"><i class="fa fa-check"></i><b>21.3</b> Curriculum</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="legal-regulations-around-ai-use.html"><a href="legal-regulations-around-ai-use.html"><i class="fa fa-check"></i><b>22</b> Legal Regulations Around AI Use</a>
<ul>
<li class="chapter" data-level="22.1" data-path="legal-regulations-around-ai-use.html"><a href="legal-regulations-around-ai-use.html#the-eu-ai-act"><i class="fa fa-check"></i><b>22.1</b> The EU AI Act</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="video-legal-regulations-around-ai-use.html"><a href="video-legal-regulations-around-ai-use.html"><i class="fa fa-check"></i><b>23</b> VIDEO Legal Regulations Around AI Use</a></li>
<li class="chapter" data-level="24" data-path="existing-laws-that-apply-to-ai.html"><a href="existing-laws-that-apply-to-ai.html"><i class="fa fa-check"></i><b>24</b> Existing Laws That Apply to AI</a>
<ul>
<li class="chapter" data-level="24.1" data-path="existing-laws-that-apply-to-ai.html"><a href="existing-laws-that-apply-to-ai.html#intellectual-property-laws"><i class="fa fa-check"></i><b>24.1</b> Intellectual Property Laws</a></li>
<li class="chapter" data-level="24.2" data-path="existing-laws-that-apply-to-ai.html"><a href="existing-laws-that-apply-to-ai.html#data-privacy-and-protection"><i class="fa fa-check"></i><b>24.2</b> Data Privacy and Protection</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="existing-laws-that-apply-to-ai.html"><a href="existing-laws-that-apply-to-ai.html#information-security"><i class="fa fa-check"></i><b>24.2.1</b> Information Security</a></li>
<li class="chapter" data-level="24.2.2" data-path="existing-laws-that-apply-to-ai.html"><a href="existing-laws-that-apply-to-ai.html#personal-information"><i class="fa fa-check"></i><b>24.2.2</b> Personal Information</a></li>
<li class="chapter" data-level="24.2.3" data-path="existing-laws-that-apply-to-ai.html"><a href="existing-laws-that-apply-to-ai.html#biometric-privacy-laws"><i class="fa fa-check"></i><b>24.2.3</b> Biometric Privacy Laws</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="existing-laws-that-apply-to-ai.html"><a href="existing-laws-that-apply-to-ai.html#liability-laws"><i class="fa fa-check"></i><b>24.3</b> Liability Laws</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="video-existing-laws-that-apply-to-ai.html"><a href="video-existing-laws-that-apply-to-ai.html"><i class="fa fa-check"></i><b>25</b> VIDEO Existing Laws That Apply to AI</a></li>
<li class="chapter" data-level="26" data-path="title.html"><a href="title.html"><i class="fa fa-check"></i><b>26</b> Title!</a></li>
<li class="chapter" data-level="27" data-path="video-title.html"><a href="video-title.html"><i class="fa fa-check"></i><b>27</b> VIDEO Title!</a></li>
<li class="chapter" data-level="28" data-path="title-1.html"><a href="title-1.html"><i class="fa fa-check"></i><b>28</b> Title!</a></li>
<li class="chapter" data-level="29" data-path="video-title-1.html"><a href="video-title-1.html"><i class="fa fa-check"></i><b>29</b> VIDEO Title!</a></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="30" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>30</b> References</a></li>
<li class="divider"></li>
<p style="text-align:center;"> <a href="https://github.com/jhudsl/OTTR_Template" target="blank" > This content was published with</a> <a href="https://bookdown.org/" target="blank"> bookdown by: </a> </p>
<p style="text-align:center;"> <a href="https://hutchdatascience.org/"> The Fred Hutch Data Science Lab </a></p>
<p style="text-align:center; font-size: 12px;"> <a href="https://github.com/rstudio4edu/rstudio4edu-book/"> Style adapted from: rstudio4edu-book </a> <a href ="https://creativecommons.org/licenses/by/2.0/"> (CC-BY 2.0) </a></p>
<p style="padding-left: 40px;"><div class="trapezoid" style = "padding-left: 40px;"><span>  <a href="https://forms.gle/W6Mg4rzuMK6Yk3Am8"> Click here to provide feedback</a> <img src="assets/itcr_arrow.png" style=" width: 10%" ></span></div></p>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">How AI Works</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<head>
  <meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=10.0,initial-scale=1.0">
  <!--script src="https://kit.fontawesome.com/6a26f47516.js"></script-->
  <!--<script src="assets/hideOutput.js"></script>-->
  <link href="assets/style.css" rel="stylesheet">
</head>
        


<div class="hero-image-container"> 
  <img class= "hero-image" src="assets/dasl_thin_main_image.png">
</div>
<div id="introduction-to-avoiding-ai-harm" class="section level1" number="16">
<h1><span class="header-section-number">Chapter 16</span> Introduction to Avoiding AI Harm</h1>
<p>This content was adapted from our course on <a href="https://hutchdatascience.org/AI_for_Efficient_Programming/ethics-of-using-ai.html">AI for Efficient Programming</a>. If you intend to use AI for writing code, we recommend that you review this content for a deeper dive into ethics specifically for writing code with generative AI.</p>
<p>The use of artificial intelligence (AI) and in particular, generative AI, has raised a number of ethical concerns. We will highlight several current concerns, however please be aware that this is a dynamic field and the possible implications of this technology is continuing to develop. It is critical that we as a society continue to evaluate and predict what the consequences of the use of AI will be, so that we can mitigate harmful effects.</p>
<p><img src="resources/images/02a-Avoiding_Harm-intro_files/figure-html/1L6-8DWn028c1o0p9gwXmz90BRcy_PjPqb683nbk1gHQ_g263a8b2455e_0_0.png" title="A cartoon of a robot thinking and text that says 'How can we use AI responsibly'." alt="A cartoon of a robot thinking and text that says 'How can we use AI responsibly'." width="100%" style="display: block; margin: auto;" /></p>
<div id="learning-objectives" class="section level2" number="16.1">
<h2><span class="header-section-number">16.1</span> Learning Objectives</h2>
<p>In this chapter we will demonstrate how to:</p>
<ul>
<li>Describe key ethical concerns for using AI tools</li>
<li>Identify possible mitigation strategies for these major concerns</li>
<li>Explain the potential benefits of being transparent about the use of AI tools to write code</li>
<li>Discuss why human contributions are still important and necessary</li>
<li>Recognize strategies for using AI tools more responsibly</li>
<li>Implement prompts to ask AI tools about responsible use</li>
</ul>
</div>
<div id="major-concerns" class="section level2" number="16.2">
<h2><span class="header-section-number">16.2</span> Major concerns</h2>
<p>In this chapter we will discuss the following issues that using AI tools may contribute to:</p>
<ol style="list-style-type: decimal">
<li><strong>Replacing Humans</strong> - AI tools can help humans, but they are not a replacement. Humans are still much better at generalizing their knowledge to other contexts.</li>
<li><strong>Inappropriate Uses</strong> - There are situations in which using AI might not be appropriate now or in the future, in which as a society we may decide humans should always be involved.</li>
<li><strong>Bias</strong> - AI models are built on data and code that were created by biased humans, thus bias can be further perpetuated.</li>
<li><strong>Misinformation and Faulty Responses</strong> - Fake or manipulated data used to help design algorithms could be believed to be correct and this could be further propagated. Text, code, etc. provided to users may not be correct or optimal for a given situation, and may have at times severe downstream consequences.</li>
<li><strong>Security or Privacy Issues</strong> - Uploading, pasting or typing in proprietary or private data, code, text, images or other files into commercial generative AI tools may be leaked not only to the developers of the commercial tool, but potentially also to other users.</li>
<li><strong>Copyright Violations</strong> - AI model responses are often not transparent about using code, text, images and other data types that may violate copyright.</li>
<li><strong>Harmful or Toxic Responses</strong> - Currently it is not clear how well generative AI models restrict harmful responses in terms of ideas, code, text, etc.</li>
<li><strong>Same Tool Over-reliance</strong> - Using a variety of tools can help reduce the potential for ethical issues that may be specific to one tool, such as bias, misinformation, and security or privacy issues.</li>
<li><strong>Lack of Education</strong> - To actually comply with ethical standards, it is vital that users be educated about best practices for use. If you help set standards for an institution or group, it strongly advised that you carefully consider how to educate individuals about those standards.</li>
</ol>
<p>Note that this is an incomplete list; additional ethical concerns will become apparent as we continue to use these new technologies. We highly suggest that users of these tools <strong>careful to learn more about the specific tools they are interested in</strong> and to be <strong>transparent</strong> about the use of these tools, so that as new ethical issues emerge, we will be better prepared to understand the implications.</p>
<div class="ethics">
<p>Be transparent about what AI tools you use where possible. This help others to better understand how you created any content that was derived by AI, as well as the possible sources that the AI tools might have used when helping you. It may also help with future unknown issues related to the use of these tools.</p>
<p>Keep in mind that some fields, organizations, and societies have guidelines or requirements for using AI, like for example the policy for the use of large language models for the <a href="https://www.iscb.org/iscb-policy-statements/iscb-policy-for-acceptable-use-of-large-language-models">International Society for Computational Biology</a>. Be aware of the requirements/guidelines for your field.</p>
</div>
<p><strong>It is essential to address these ethical concerns and ensure that AI is used in a responsible and transparent manner.</strong> This could be done through ensuring the quality of training for AI systems, promoting transparency about AI-generated content, and implementing safeguards against the creation of harmful or biased content. By doing so, we can harness the potential of AI to improve and transform the way we work while maintaining ethical standards.</p>
<p><strong>Recognize that the ethical guidelines and standards for your field should be considered when using AI or creating AI use policies.</strong></p>
</div>
<div id="replacing-humans" class="section level2" number="16.3">
<h2><span class="header-section-number">16.3</span> Replacing Humans</h2>
<p>Those who use AI tools need to recognize their own value in the process. While AI systems are useful, they <strong>do not replace the strengths that humans have</strong> for innovating new ideas or methods, for evaluating how the content generated by AI integrates into the larger picture of a project, or in evaluating the downstream consequences of the content.</p>
<p>Computer science is a field that has historically lacked diversity. It is critical that we support diverse new learners of computer science, as we will continue to need human involvement in the development and use of AI tools. This can help to ensure that more diverse perspectives are accounted for in our understanding of how these tools should be used responsibly.</p>
<div id="tips-for-supporting-human-contributions" class="section level3" number="16.3.1">
<h3><span class="header-section-number">16.3.1</span> Tips for supporting human contributions</h3>
<ul>
<li>Avoid thinking that content by AI tools must be better than that created by humans, as this is not true.</li>
<li>Recall that humans wrote the code to create these AI tools and that the data used to train these AI tools also came from humans. Many of the large commercial AI tools were trained on websites and other content from the internet.</li>
<li>Be transparent where possible about when you do or do not use AI tools, give credit to the humans involved as much as possible.</li>
</ul>
<div class="ethics">
<p>A new term in the medical field called <a href="https://www.technologyreview.com/2023/04/21/1071921/ai-is-infiltrating-health-care-we-shouldnt-let-it-make-decisions/">AI paternalism</a> describes the concept that doctors (and others) may trust AI over their own judgment or the experiences of the patients they treat. This has already been shown to be a problem with earlier AI systems intended to help distinguish patient groups. Not all humans will necessarily fit the expectations of the AI model if it is not very good at predicting edge cases <span class="citation">(<a href="references.html#ref-AI_paternalism" role="doc-biblioref">Hamzelou n.d.</a>)</span>. Therefore, in all fields it is important for us to not forget our value as humans in our understanding of the world.</p>
</div>
</div>
</div>
<div id="inappropriate-uses" class="section level2" number="16.4">
<h2><span class="header-section-number">16.4</span> Inappropriate Uses</h2>
<p>There are situations in which we may, as a society, not want an automated response. There may even be situations in which we do not want to bias our own human judgment by that of an AI system. There may be other situations where the efficiency of AI may also be considered inappropriate. While many of these topics are still under debate and AI technology continues to improve, we challenge the readers to consider such cases given what is currently possible and what may be possible in the future.</p>
<p>Some reasons why AI may not be appropriate for certain situation include:</p>
<ul>
<li>Despite the common misconception that AI systems have clearer judgement than humans, they are in fact typically just as prone to bias and sometimes even exacerbate bias (<span class="citation">Pethig and Kroenung (<a href="references.html#ref-pethig_biased_2023" role="doc-biblioref">2023</a>)</span>). There are some very mindful researchers working on these issues in specific contexts and making progress where AI may actually improve on human judgement, but generally speaking AI systems are currently typically biased and reflective of human judgement but in a more limited manner based on the context in which they have been trained.</li>
<li>AI systems can behave in unexpected ways (<span class="citation">Gichoya et al. (<a href="references.html#ref-gichoya_ai_2022" role="doc-biblioref">2022</a>)</span>).</li>
<li>Humans are still better than AI at generalizing what they learn for new contexts.</li>
<li>Humans can better understand the consequences of discussions from a humanity standpoint.</li>
</ul>
<p>Some examples where it may be considered inappropriate for AI systems to be used include:</p>
<ul>
<li>In the justice system to determine if someone is guilty of a crime or to determine the punishment of someone found guilty of a crime.</li>
<li>It may be considered inappropriate for AI systems to be used in certain warfare circumstances.</li>
</ul>
<div id="tips-for-avoiding-inappropriate-uses" class="section level3" number="16.4.1">
<h3><span class="header-section-number">16.4.1</span> Tips for avoiding inappropriate uses</h3>
<ul>
<li>Stay up-to-date on current practices and standards for your field, as well as up-to-date on the news for how others have experienced their use of AI.</li>
<li>Stay involved in discussions about appropriate uses for AI, particularly for policy.</li>
<li>Begin using AI slowly and iteratively to allow time to determine the appropriateness of the use. Some issues will only be discovered after some experience.</li>
<li>Involve a diverse group of individuals in discussions of intended uses to better account for a variety of perspectives.</li>
<li>Seek outside expert opinion whenever you are unsure about your AI use plans.</li>
<li>Consider AI alternatives if something doesn’t feel right.</li>
</ul>
</div>
</div>
<div id="bias" class="section level2" number="16.5">
<h2><span class="header-section-number">16.5</span> Bias</h2>
<p>One of the biggest concerns is the potential for AI to create biased code. AI systems are trained on data created by humans. If this data used to train the system is biased (and this includes existing code that may be written in a biased manner), the resulting content from the AI tools could also be biased. This could lead to discrimination, abuse, or neglect for certain groups of people, such as those with certain ethnic or cultural backgrounds, genders, ages, sexuality, capabilities, religions or other group affiliations.</p>
<p>It is well known that data and code are often biased <span class="citation">(<a href="references.html#ref-belenguer_ai_2022" role="doc-biblioref">Belenguer 2022</a>)</span>. The resulting output of AI tools should be evaluated for bias and modified where needed. Please be aware that because bias is intrinsic, it may be difficult to identify issues. Therefore, people with specialized training to recognize bias should be consulted. It is also vital that evaluations be made throughout the software development process of new AI tools to check for and consider potential perpetuation of bias.</p>
<div id="tips-for-avoiding-bias" class="section level3" number="16.5.1">
<h3><span class="header-section-number">16.5.1</span> Tips for avoiding bias</h3>
<ul>
<li>Be aware of the biases in the data that is used to train AI systems.</li>
<li>Check for possible biases within data used to train new AI tools.
<ul>
<li>Are there harmful data values? Examples could include discriminatory and false associations.</li>
<li>Are the data adequately inclusive? Examples could include a lack of data about certain ethnic or gender groups or disabled individuals, which could result in code that does not adequately consider these groups, ignores them all together, or makes false associations.</li>
<li>Are the data of high enough quality? Examples could include data that is false about certain individuals.</li>
</ul></li>
<li>Evaluate the code for new AI tools for biases as it is developed. Check if any of the criteria for weighting certain data values over others are rooted in bias.</li>
<li>Consider the possible outcomes of the use of content created by AI tools. Consider if the content could possibly be used in a manner that will result in discrimination.</li>
</ul>
<p>See <span class="citation">Belenguer (<a href="references.html#ref-belenguer_ai_2022" role="doc-biblioref">2022</a>)</span> for more guidance. We also encourage you to check out the following video for a classic example of bias in AI:</p>
<iframe src="https://www.youtube.com/embed/TWWsW1w-BVo?si=YLGbpVKrUz5b56vM" width="90%" height="400px">
</iframe>
<p>For further details check out this <a href="https://www.coursera.org/learn/algorithmic-fairness">course</a> on Coursera about building fair algorithms. We will also describe more in the next section.</p>
</div>
</div>
<div id="misinformation-and-faulty-responses" class="section level2" number="16.6">
<h2><span class="header-section-number">16.6</span> Misinformation and Faulty Responses</h2>
<p>AI tools use data that may contain false or incorrect information and may therefore respond with content that is also false or incorrect.</p>
<p>This is due to number of reasons:</p>
<ul>
<li>AI tools may “hallucinate” fake response based on artifacts of the algorithm</li>
<li>AI tools may be trained on data that is out-of-date</li>
<li>AI tools may be trained on data that has fake or incorrect information</li>
<li>AI tools are not necessarily trained for every intended use and may therefore may not reflect best practices for a given task or field</li>
</ul>
<p>AI tools may also report data as if it is real, when it is in fact not real. For example, currently at the time of the writing of this course, ChatGPT will report citations with links that are not always correct. Furthermore, AI models can “hallucinate” incorrect responses based on artifacts of the algorithm underneath the tool. These responses are essentially made up by the tool. It is difficult to know when a tool is hallucinating especially if it is a tool that you did not create, therefore it is important to review and check responses from AI tools. There is also a risk that content written with AI tools, may be incorrect or inappropriate for the given context of intended use, or they may not reflect best practices for a given context or field. The tools are limited to the data they were trained on, which may not reflect your intended use.</p>
<p>It is also important to remember that content generated by AI tools is not necessarily better than content written by humans. It requires just as much, if not more review.</p>
<div id="tips-for-reducing-misinformation-faulty-responses" class="section level3" number="16.6.1">
<h3><span class="header-section-number">16.6.1</span> Tips for reducing misinformation &amp; faulty responses</h3>
<ul>
<li>Be aware that some AI tools currently make up false information based on artifacts of the algorithm called hallucinations or based on false information in the training data.</li>
<li>Do not assume that the content generated by AI is real or correct.</li>
<li>Realize that AI is only as good or up-to-date as what it was trained on, the content may be generated using out-of-date data. Look up responses to ensure it is up-to-date.</li>
<li>In many cases <strong>utilizing multiple AI tools</strong> can help you to <strong>cross-check</strong> the responses (however be careful about the privacy of each tool if you use any private or propriety data in your prompts!).</li>
<li>Ask the AI tools for extra information about if there are any potential limitations or weaknesses in the responses, but keep in mind that the tool may not be aware of issues and therefore human review is required. The information provided by the tool can however be a helpful starting point.</li>
</ul>
<div class="query">
<p>Are there any limitations associated with this response?</p>
</div>
<div class="query">
<p>What assumptions were made in creating this content?</p>
</div>
<div class="ethics">
<p><a href="https://stackoverflow.com/">Stack Overflow</a>, a popular community-based website where programmers help one another, has (at the time of writing this) temporarily <a href="https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned">banned</a> users from answering questions with AI-generated code. This is because users were posting incorrect answers to questions. It is important to follow this policy (as you may face removal from the community). This policy goes to show that you really need to check the code that you get from AI models. While they are currently helpful tools, they do not know everything.</p>
</div>
</div>
</div>
<div id="lack-of-interpretability" class="section level2" number="16.7">
<h2><span class="header-section-number">16.7</span> Lack of Interpretability</h2>
<p>There is risk in using AI tools, that we may encounter situations where it is unclear why the AI system came to a particular result. AI systems that use more complicated algorithms can make it difficult to trace back the decision process of the algorithm.
Using content created or modified by AI, could make it difficult for others to understand if the content is adequate or appropriate, or to identify and fix any issues that may arise.</p>
<p>This could result in negative consequences, such as for example reliance on a system that distinguishes consumers or patients based on an arbitrary factor that is actually not consequential. Decisions based on AI responses therefore need to be made extra carefully and with clarity about why the AI system may be indicating various trends or predictions.</p>
<div id="tips-for-avoiding-a-lack-of-interpretability" class="section level3" number="16.7.1">
<h3><span class="header-section-number">16.7.1</span> Tips for avoiding a lack of interpretability</h3>
<ul>
<li>Content should be reviewed by those experienced in the given field.</li>
<li>Ask AI tools to help you understand the how it got to the response that it did, but get expert assistance where needed.</li>
</ul>
<div class="query">
<p>Can you explain how you generated this response?</p>
</div>
<p><img src="resources/images/02a-Avoiding_Harm-intro_files/figure-html/1L6-8DWn028c1o0p9gwXmz90BRcy_PjPqb683nbk1gHQ_g263a8b2455e_0_157.png" title="Cartoon of a robot that says AI can assist us in utilizing AI technology more responsibly, if we ask for the right help." alt="Cartoon of a robot that says AI can assist us in utilizing AI technology more responsibly, if we ask for the right help." width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="security-and-privacy-issues" class="section level2" number="16.8">
<h2><span class="header-section-number">16.8</span> Security and Privacy issues</h2>
<p>Commercial AI tools are often not designed to protect users from unknowingly submitting prompts that include propriety are private information. Different AI tools have different practices in terms of how they do or do not collect data about the prompts that people submit. They also have different practices in terms of if they reuse information from prompts to other users. Thus if users submit prompts that include propriety or private information, they run the risk of that information being viewable not only by the developers/maintainers of the AI tool used, but also by other users who use that same AI tool. Note that the AI system itself may not be trained on responses for how prompt data is collected or not.</p>
<p>Furthermore, AI tools are not always trained in a way that is particularly conscious of data security. If for example, code is written using these tools by users who are less familiar with coding security concerns, protected data or important passwords may be leaked within the code itself. AI systems may also utilize data that was actually intended to be private.</p>
<p>It is also important to consider what data your the responses that you get from an AI tool might actually be using.</p>
<div id="tips-for-reducing-security-and-privacy-issues" class="section level3" number="16.8.1">
<h3><span class="header-section-number">16.8.1</span> Tips for reducing security and privacy issues</h3>
<ul>
<li>Check that no sensitive data, such as Personal Identifiable Information (PII) or propriety information becomes public through prompts to commercial AI systems.</li>
<li>Consider purchasing a license for a private AI system if needed or create your own if you wish to work with sensitive data (seek expert guidance to determine if the AI systems are secure enough).</li>
<li>Promote for regulation of AI tools by voting for standards where possible.</li>
<li>Ask AI tools for help with security when using commercial tools, but to not rely on them alone. In some cases, commercial AI tools will even provide little guidance about who developed the tool and what data it was trained on, regardless of what happens to the prompts and if they are collected and maintained in a secure way.</li>
<li>Consult with an expert about data security if you want to design or use a AI tool that will regularly use private or propriety data.</li>
</ul>
<div class="query">
<p>Are there any possible data security or privacy issues associated with the plan you proposed?</p>
</div>
</div>
</div>
<div id="violating-copyright" class="section level2" number="16.9">
<h2><span class="header-section-number">16.9</span> Violating Copyright</h2>
<p>When AI systems are trained on data, they may also learn and incorporate copyrighted information. This means that AI-generated content could potentially infringe on the copyright of the original author. For example, if an AI system is trained on a code written by a human programmer, the AI system could generate code that is identical to or similar to the code from that author. If the AI system then uses this code without permission from the original author, this could constitute copyright infringement.</p>
<p>Similarly, AI systems could potentially infringe on intellectual property rights by using code that is protected by trademarks or patents. For example, if an AI system is trained on a training manual that contains code that is protected by a trademark, the AI system could generate code that is identical to or similar to the code in the training manual. If the AI system then uses this code without permission from the trademark owner, this could constitute trademark infringement.</p>
<div id="tips-for-avoiding-copyright-violations" class="section level3" number="16.9.1">
<h3><span class="header-section-number">16.9.1</span> Tips for avoiding copyright violations</h3>
<ul>
<li>Be transparent about what AI tools you use to write your code.</li>
<li>Obtain permission from the copyright holders of any content that you use to train an AI system. Only use content that has been licensed for use.</li>
<li>Cite all content that you can.</li>
<li>Ask the AI tools if the content it helped generate used any content that you can cite.</li>
</ul>
<div class="query">
<p>Did this content use any content from others that I can cite?</p>
</div>
</div>
</div>
<div id="harmful-or-toxic-responses" class="section level2" number="16.10">
<h2><span class="header-section-number">16.10</span> Harmful or Toxic Responses</h2>
<p>Another major concern is the use of AI to generate malicious content or that AI itself may accidentally create harmful responses. For instance, AI could start suggesting the creation of code that spreads malware or hacks into computer systems. Another issue is what is called <a href="https://towardsdatascience.com/toxicity-in-ai-text-generation-9e9d9646e68f">“toxicity”</a>, which refers to disrespectful, rude, or hateful responses (<span class="citation">Nikulski (<a href="references.html#ref-nikulski_toxicity_2021" role="doc-biblioref">2021</a>)</span>). These responses can have very negative consequences for users. Ultimately both issues could cause severe damage to individuals and organizations, including data breaches and financial losses. AI systems need to be designed with safeguards to avoid harmful responses, to test for such responses, and to ensure that the system is not infiltrated by additional possibly harmful parties.</p>
<div id="tips-for-avoiding-the-creation-of-harmful-content" class="section level3" number="16.10.1">
<h3><span class="header-section-number">16.10.1</span> Tips for avoiding the creation of harmful content</h3>
<ul>
<li>Be careful about what commercial tools you employ, they should be transparent about what they do to avoid harm.</li>
<li>If designing a system, ensure that best practices are employed to avoid harmful responses. This should be done during the design process and should the system should also be regularly evaluated. Some development systems such as <a href="https://aws.amazon.com/blogs/aws/evaluate-compare-and-select-the-best-foundation-models-for-your-use-case-in-amazon-bedrock-preview/">Amazon Bedrock</a> have tools for evaluating <a href="https://towardsdatascience.com/toxicity-in-ai-text-generation-9e9d9646e68f">toxicity</a> to test for harmful responses. Although such systems can be helpful to automatically test, evaluation should also be done directly by humans.</li>
<li>Be careful about the context in which you might have people use AI - will they know how to use it responsibly?</li>
<li>Be careful about what content you share publicly, as it could be used for malicious purposes.</li>
<li>Consider how the content might be used by others.</li>
<li>Ask the AI tools to help you, but do not rely on them alone.</li>
</ul>
<div class="query">
<p>What are the possible downstream uses of this content?</p>
</div>
<div class="query">
<p>What are some possible negative consequences of using this content?</p>
</div>
</div>
</div>
<div id="same-tool-over-reliance" class="section level2" number="16.11">
<h2><span class="header-section-number">16.11</span> Same Tool Over-reliance</h2>
<p>Only using one AI tool can increase the risk of the ethical issues discussed. For example, it may be easier to determine if a tool incorrect about a response if we see that a variety of tools have different answers to the same prompt. Secondly, as our technology evolves, some tools may perform better than others at specific tasks. It is also necessary to check responses over time with the same tool, to verify that a result is even consistent from the same tool.</p>
<div id="tips-for-avoiding-over-reliance" class="section level3" number="16.11.1">
<h3><span class="header-section-number">16.11.1</span> Tips for avoiding over-reliance</h3>
<ul>
<li>Check that each tool you are using meets the privacy and security restrictions that you need.</li>
<li>Utilize platforms that make it easier to use multiple AI tools, such as <a href="https://poe.com/" class="uri">https://poe.com/</a>, which as access to many tools, or <a href="https://aws.amazon.com/about-aws/whats-new/2023/11/evaluate-compare-select-fms-use-case-amazon-bedrock/">Amazon Bedrock</a>, which actually has a feature to send the same prompt to multiple tools automatically, including for more advanced usage in the development of models based on modifying existing foundation models.</li>
<li>Evaluate the results of the same prompt multiple times with the same tool to see how consistent it is overtime.</li>
<li>Use slightly different prompts to see how the response may change with the same tool.</li>
<li>Consider if using different types of data maybe helpful for answering the same question.</li>
</ul>
</div>
</div>
<div id="lack-of-education" class="section level2" number="16.12">
<h2><span class="header-section-number">16.12</span> Lack of education</h2>
<p>There are many studies indicating that individuals typically want to comply with ethical standards, but it becomes difficult when they do not know how (<span class="citation">Giorgini et al. (<a href="references.html#ref-giorgini_researcher_2015" role="doc-biblioref">2015</a>)</span>). Furthermore, individuals who receive training are much more likely to adhere to standards (<span class="citation">Kowaleski, Sutherland, and Vetter (<a href="references.html#ref-kowaleski_can_2019" role="doc-biblioref">2019</a>)</span>).</p>
<p>Properly educating those you wish to comply with standards, can better ensure that compliance actually happens.</p>
<p>It is especially helpful if training materials are developed to be especially relevant to the actually potential uses by the individuals receiving training and if the training includes enough fundamentals so that individuals understand why policies are in place.</p>
<div class="example">
<p><span id="exm:unlabeled-div-1" class="example"><strong>Example 16.1  </strong></span><strong>Real World Example</strong></p>
<p>A lack of proper training at Samsung lead to a leak of proprietary data due to unauthorized use of ChatGPT by employees – see <a href="https://cybernews.com/news/chatgpt-samsung-data-leak" class="uri">https://cybernews.com/news/chatgpt-samsung-data-leak</a> for more details:</p>
<blockquote>
<p>“The information employees shared with the chatbot supposedly included the source code of software responsible for measuring semiconductor equipment. A Samsung worker allegedly discovered an error in the code and queried ChatGPT for a solution.</p>
</blockquote>
<blockquote>
<p>OpenAI explicitly tells users not to share “any sensitive information in your conversations” in the company’s frequently asked questions (FAQ) section. Information that users directly provide to the chatbot is used to train the AI behind the bot.</p>
</blockquote>
<blockquote>
<p>Samsung supposedly discovered three attempts during which confidential data was revealed. Workers revealed restricted equipment data to the chatbot on two separate occasions and once sent the chatbot an excerpt from a corporate meeting.
Privacy concerns over ChatGPT’s security have been ramping up since OpenAI revealed that a flaw in its bot exposed parts of conversations users had with it, as well as their payment details in some cases.
As a result, the Italian Data Protection Authority has banned ChatGPT, while German lawmakers have said they could follow in Italy’s footsteps.”</p>
</blockquote>
</div>
<div id="tips-to-avoid-a-lack-of-education" class="section level3" number="16.12.1">
<h3><span class="header-section-number">16.12.1</span> Tips to avoid a lack of education</h3>
<ul>
<li>Emphasize the importance of training and education</li>
<li>Recognize that general AI literacy to better understand how AI works, can help individuals use AI more responsibly.</li>
<li>Seek existing education content made by experts that can possibly be modified for your use case</li>
<li>Consider how often people will need to be reminded about best practices. Should training be required regularly? Should individuals receive reminders about best practices especially in contexts in which they might use AI tools.</li>
<li>Make your best practices easily findable and help point people to the right individuals to ask for guidance.</li>
<li>Recognize that best practices for AI will likely change frequently in the near future as the technology evolves, education content should be updated accordingly.</li>
</ul>
</div>
</div>
<div id="summary" class="section level2" number="16.13">
<h2><span class="header-section-number">16.13</span> Summary</h2>
<p>Here is a summary of all the tips we suggested:</p>
<div class="ethics">
<ul>
<li>Disclose when you use AI tools to create content.</li>
<li>Be aware that AI systems are biased and their responses are likely biased. Any content generated by an AI system should be evaluated for potential bias.</li>
<li>Be aware that AI systems may behave in unexpected ways. Implement new AI solutions slowly to account for the unexpected. Test those systems and try to better understand how they work in different contexts.</li>
<li>Be aware that humans are still better at generalizing concepts to other contexts.</li>
<li>Carefully consider if an AI solution is appropriate for your context.</li>
<li>Credit human authors by citing them and adhering to copyright restrictions.</li>
<li>Ensure that prompts to commercial tools don’t include private or propriety data or information.</li>
<li>Cross-check content from AI tools by using multiple AI tools - but check that each tool meets the privacy and security restrictions that you need.</li>
<li>Don’t assume AI-generated content is real, accurate, consistent, current, or better than that of a human.</li>
<li>Ask the AI tools to help you understand:
<ul>
<li>Sources for the content that you can cite</li>
<li>Any decision processes in how the content was created</li>
<li>Potential limitations</li>
<li>Potential security or privacy issues</li>
<li>Potential downstream consequences of the use of the content</li>
</ul></li>
<li>Always have expert humans review the content and value your own contributions and thoughts.</li>
<li>Emphasize training and education about AI and recognize that best practices will evolve as the technology evolves.</li>
</ul>
</div>
<p>Overall, we hope that these guidelines and tips will help us all use AI tools more responsibly. We recognize however, that as this is emerging technology and more ethical issues will emerge as we continue to use these tools in new ways. AI tools can even help us to use them more responsibly when we ask the right additional questions, but remember that human review is always necessary. Staying up-to-date on the current ethical considerations will also help us all continue to use AI responsibly.</p>

</div>
</div>
<hr>
<center> 
  <div class="footer">
      All illustrations <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY. </a>
      <br>
      All other materials <a href= "https://creativecommons.org/licenses/by/4.0/"> CC-BY </a> unless noted otherwise.
      <a href="https://hutchdatascience.org/" target="_blank"><img src="https://hutchdatascience.org/images/crazy-idea-wide.png" style="width: 80%; padding-left: 15px; padding-top: 8px;"</a>
  </div>
</center>
            </section>

          </div>
        </div>
      </div>
<a href="video-knowing-the-ground-rules.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="consent-and-ai.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
