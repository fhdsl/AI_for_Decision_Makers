<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Societal Impact | AI for Decision Makers</title>
  <meta name="description" content="Description about Course/Book." />
  <meta name="generator" content="bookdown 0.39.1 and GitBook 2.6.7" />

  <meta property="og:title" content="Societal Impact | AI for Decision Makers" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Description about Course/Book." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Societal Impact | AI for Decision Makers" />
  
  <meta name="twitter:description" content="Description about Course/Book." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/favicon.ico" type="image/x-icon" />
<link rel="prev" href="introduction-to-avoiding-ai-harm.html"/>
<link rel="next" href="algorithm-considerations.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-YLGCFXEHPV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-YLGCFXEHPV');
  </script>





<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="assets/style.css" type="text/css" />
<link rel="stylesheet" href="assets/style_custom.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<a href="https://hutchdatascience.org/" target="_blank"><img src="assets/big-dasl-stacked.png" style="width: 80%; padding-left: 34px; padding-top: 8px;"</a>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Course</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#specialization-sections"><i class="fa fa-check"></i>Specialization Sections</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#available-course-formats"><i class="fa fa-check"></i>Available course formats</a></li>
</ul></li>
<li class="part"><span><b>Introduction</b></span></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#motivation"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#target-audience"><i class="fa fa-check"></i>Target Audience</a></li>
</ul></li>
<li class="part"><span><b>Exploring AI Possibilities</b></span></li>
<li class="chapter" data-level="" data-path="introduction-to-exploring-ai-possibilities.html"><a href="introduction-to-exploring-ai-possibilities.html"><i class="fa fa-check"></i>Introduction to Exploring AI Possibilities</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-exploring-ai-possibilities.html"><a href="introduction-to-exploring-ai-possibilities.html#introduction-1"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="introduction-to-exploring-ai-possibilities.html"><a href="introduction-to-exploring-ai-possibilities.html#motivation-1"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="" data-path="introduction-to-exploring-ai-possibilities.html"><a href="introduction-to-exploring-ai-possibilities.html#target-audience-1"><i class="fa fa-check"></i>Target Audience</a></li>
<li class="chapter" data-level="" data-path="introduction-to-exploring-ai-possibilities.html"><a href="introduction-to-exploring-ai-possibilities.html#curriculum"><i class="fa fa-check"></i>Curriculum</a></li>
<li class="chapter" data-level="" data-path="introduction-to-exploring-ai-possibilities.html"><a href="introduction-to-exploring-ai-possibilities.html#learning-objectives"><i class="fa fa-check"></i>Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html"><i class="fa fa-check"></i>What Is Artificial Intelligence</a>
<ul>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html#specific-and-general-intelligence"><i class="fa fa-check"></i>Specific and General Intelligence</a></li>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html#shifting-goalposts"><i class="fa fa-check"></i>Shifting Goalposts</a></li>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html#our-ai-definition"><i class="fa fa-check"></i>Our AI Definition</a></li>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html#what-is-and-is-not-ai"><i class="fa fa-check"></i>What Is and Is Not AI</a>
<ul>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html#smartphones"><i class="fa fa-check"></i>Smartphones</a></li>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html#calculators"><i class="fa fa-check"></i>Calculators</a></li>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html#computer-programs"><i class="fa fa-check"></i>Computer Programs</a></li>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html#examples-of-ai-in-the-real-world"><i class="fa fa-check"></i>Examples of AI In the Real World</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-is-artificial-intelligence.html"><a href="what-is-artificial-intelligence.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="discussion-is-it-ai.html"><a href="discussion-is-it-ai.html"><i class="fa fa-check"></i>DISCUSSION Is It AI</a></li>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html"><i class="fa fa-check"></i>How AI Works</a>
<ul>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#early-warning-for-skin-cancer"><i class="fa fa-check"></i>Early Warning for Skin Cancer</a></li>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#collecting-datapoints"><i class="fa fa-check"></i>Collecting Datapoints</a>
<ul>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#what-is-data"><i class="fa fa-check"></i>What Is Data</a></li>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#preparing-the-data"><i class="fa fa-check"></i>Preparing the Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#understanding-the-algorithm"><i class="fa fa-check"></i>Understanding the Algorithm</a>
<ul>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#testing-the-algorithm"><i class="fa fa-check"></i>Testing the Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#interfacing-with-ai"><i class="fa fa-check"></i>Interfacing with AI</a></li>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#understanding-the-ai-spring"><i class="fa fa-check"></i>Understanding the AI Spring</a>
<ul>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#transformer-models"><i class="fa fa-check"></i>Transformer Models</a></li>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#diffusion-models"><i class="fa fa-check"></i>Diffusion Models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="how-ai-works.html"><a href="how-ai-works.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="discussion-how-ai-works.html"><a href="discussion-how-ai-works.html"><i class="fa fa-check"></i>DISCUSSION How AI Works</a></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html"><i class="fa fa-check"></i>Demystifying Types of AI</a>
<ul>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#machine-learning"><i class="fa fa-check"></i>Machine Learning</a>
<ul>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#neural-networks"><i class="fa fa-check"></i>Neural Networks</a></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#deep-learning"><i class="fa fa-check"></i>Deep Learning</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#generative-ai"><i class="fa fa-check"></i>Generative AI</a>
<ul>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#transformer-models-and-architecture"><i class="fa fa-check"></i>Transformer Models and Architecture</a></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#large-language-model"><i class="fa fa-check"></i>Large Language Model</a></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#diffusion-model"><i class="fa fa-check"></i>Diffusion Model</a></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#variational-autoencoders-vaes"><i class="fa fa-check"></i>Variational Autoencoders (VAEs)</a></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#generative-adversarial-networks-gans"><i class="fa fa-check"></i>Generative Adversarial Networks (GANs)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#natural-language-processing"><i class="fa fa-check"></i>Natural Language Processing</a></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#strengths-and-weaknesses"><i class="fa fa-check"></i>Strengths and Weaknesses</a></li>
<li class="chapter" data-level="" data-path="demystifying-types-of-ai.html"><a href="demystifying-types-of-ai.html#summary-2"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="discussion-ai-types.html"><a href="discussion-ai-types.html"><i class="fa fa-check"></i>DISCUSSION AI Types</a></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html"><i class="fa fa-check"></i>What AI Makes Possible</a>
<ul>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#advancements-in-text-mining"><i class="fa fa-check"></i>Advancements in Text Mining</a>
<ul>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#examples"><i class="fa fa-check"></i>Examples</a></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#extracting-population-statistics"><i class="fa fa-check"></i>Extracting Population Statistics</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#modifying-and-generating-text"><i class="fa fa-check"></i>Modifying and Generating Text</a>
<ul>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#examples-1"><i class="fa fa-check"></i>Examples</a></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#transforming-an-angry-email"><i class="fa fa-check"></i>Transforming an Angry Email</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#automating-tedious-processes"><i class="fa fa-check"></i>Automating Tedious Processes</a>
<ul>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#examples-2"><i class="fa fa-check"></i>Examples</a></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#meeting-note-takers"><i class="fa fa-check"></i>Meeting Note Takers</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#idea-generation"><i class="fa fa-check"></i>Idea Generation</a>
<ul>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#diabetes-gene-hypotheses"><i class="fa fa-check"></i>Diabetes Gene Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#planning-and-organizing"><i class="fa fa-check"></i>Planning and Organizing</a>
<ul>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#meeting-agendas"><i class="fa fa-check"></i>Meeting Agendas</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#synthetic-data-generation"><i class="fa fa-check"></i>Synthetic Data Generation</a></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#text-to-speech-to-text"><i class="fa fa-check"></i>Text to Speech to Text</a></li>
<li class="chapter" data-level="" data-path="what-ai-makes-possible.html"><a href="what-ai-makes-possible.html#interactive-help"><i class="fa fa-check"></i>Interactive Help</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="discussion-ai-possibilities.html"><a href="discussion-ai-possibilities.html"><i class="fa fa-check"></i>DISCUSSION AI Possibilities</a></li>
<li class="chapter" data-level="" data-path="ground-rules-for-ai.html"><a href="ground-rules-for-ai.html"><i class="fa fa-check"></i>Ground Rules for AI</a></li>
<li class="chapter" data-level="" data-path="ai-possibilities-case-studies.html"><a href="ai-possibilities-case-studies.html"><i class="fa fa-check"></i>AI Possibilities Case Studies</a>
<ul>
<li class="chapter" data-level="" data-path="ai-possibilities-case-studies.html"><a href="ai-possibilities-case-studies.html#financial-forecasting"><i class="fa fa-check"></i>Financial Forecasting</a>
<ul>
<li class="chapter" data-level="" data-path="ai-possibilities-case-studies.html"><a href="ai-possibilities-case-studies.html#categorizing-businesses"><i class="fa fa-check"></i>Categorizing Businesses</a></li>
<li class="chapter" data-level="" data-path="ai-possibilities-case-studies.html"><a href="ai-possibilities-case-studies.html#incorporating-new-predictors-for-forecasting"><i class="fa fa-check"></i>Incorporating new predictors for forecasting</a></li>
<li class="chapter" data-level="" data-path="ai-possibilities-case-studies.html"><a href="ai-possibilities-case-studies.html#using-large-language-models-to-predict-inflation"><i class="fa fa-check"></i>Using Large Language Models to predict inflation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Avoiding AI Harm</b></span></li>
<li class="chapter" data-level="" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html"><i class="fa fa-check"></i>Introduction to Avoiding AI Harm</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#motivation-2"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#target-audience-2"><i class="fa fa-check"></i>Target Audience</a></li>
<li class="chapter" data-level="" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#curriculum-1"><i class="fa fa-check"></i>Curriculum</a></li>
<li class="chapter" data-level="" data-path="introduction-to-avoiding-ai-harm.html"><a href="introduction-to-avoiding-ai-harm.html#learning-objectives-1"><i class="fa fa-check"></i>Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html"><i class="fa fa-check"></i>Societal Impact</a>
<ul>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#guidelines-for-responsible-development-and-use-of-ai."><i class="fa fa-check"></i>Guidelines for Responsible Development and Use of AI.</a></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#major-ethical-considerations"><i class="fa fa-check"></i>Major Ethical Considerations</a></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#intentional-and-inadvertent-harm"><i class="fa fa-check"></i>Intentional and Inadvertent Harm</a>
<ul>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#tips-for-avoiding-inadvertent-harm"><i class="fa fa-check"></i>Tips for avoiding inadvertent harm</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#replacing-humans"><i class="fa fa-check"></i>Replacing Humans</a>
<ul>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#tips-for-supporting-human-contributions"><i class="fa fa-check"></i>Tips for supporting human contributions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#inappropriate-use-and-lack-of-oversight"><i class="fa fa-check"></i>Inappropriate Use and Lack of Oversight</a>
<ul>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#tips-for-avoiding-inappropriate-uses-and-lack-of-oversight"><i class="fa fa-check"></i>Tips for avoiding inappropriate uses and lack of oversight</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#bias-perpetuation-and-disparities"><i class="fa fa-check"></i>Bias Perpetuation and Disparities</a>
<ul>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#tips-for-avoiding-bias"><i class="fa fa-check"></i>Tips for avoiding bias</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#security-and-privacy-issues"><i class="fa fa-check"></i>Security and Privacy Issues</a>
<ul>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#use-the-right-tool-for-the-job"><i class="fa fa-check"></i>Use the right tool for the job</a></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#ai-can-have-security-blind-spots"><i class="fa fa-check"></i>AI can have security blind spots</a></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#data-source-issues"><i class="fa fa-check"></i>Data source issues</a></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#tips-for-reducing-security-and-privacy-issues"><i class="fa fa-check"></i>Tips for reducing security and privacy issues</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#climate-impact"><i class="fa fa-check"></i>Climate Impact</a></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#tips-for-reducing-climate-impact"><i class="fa fa-check"></i>Tips for reducing climate impact</a></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#transparency"><i class="fa fa-check"></i>Transparency</a>
<ul>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#tips-for-being-transparent"><i class="fa fa-check"></i>Tips for being transparent</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="societal-impact.html"><a href="societal-impact.html#summary-3"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="algorithm-considerations.html"><a href="algorithm-considerations.html"><i class="fa fa-check"></i>Algorithm considerations</a>
<ul>
<li class="chapter" data-level="" data-path="algorithm-considerations.html"><a href="algorithm-considerations.html#harmful-or-toxic-responses"><i class="fa fa-check"></i>Harmful or Toxic Responses</a>
<ul>
<li class="chapter" data-level="" data-path="algorithm-considerations.html"><a href="algorithm-considerations.html#tips-for-avoiding-the-creation-of-harmful-content"><i class="fa fa-check"></i>Tips for avoiding the creation of harmful content</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="algorithm-considerations.html"><a href="algorithm-considerations.html#lack-of-interpretability"><i class="fa fa-check"></i>Lack of Interpretability</a>
<ul>
<li class="chapter" data-level="" data-path="algorithm-considerations.html"><a href="algorithm-considerations.html#tips-for-avoiding-a-lack-of-interpretability"><i class="fa fa-check"></i>Tips for avoiding a lack of interpretability</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="algorithm-considerations.html"><a href="algorithm-considerations.html#misinformation-and-faulty-responses"><i class="fa fa-check"></i>Misinformation and Faulty Responses</a>
<ul>
<li class="chapter" data-level="" data-path="algorithm-considerations.html"><a href="algorithm-considerations.html#tips-for-reducing-misinformation-faulty-responses"><i class="fa fa-check"></i>Tips for reducing misinformation &amp; faulty responses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="algorithm-considerations.html"><a href="algorithm-considerations.html#summary-4"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html"><i class="fa fa-check"></i>Adherence practices</a>
<ul>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html#start-slow"><i class="fa fa-check"></i>Start Slow</a>
<ul>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html#tips-for-starting-slow"><i class="fa fa-check"></i>Tips for starting slow</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html#check-for-allowed-use"><i class="fa fa-check"></i>Check for Allowed Use</a>
<ul>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html#tips-for-checking-for-allowed-use"><i class="fa fa-check"></i>Tips for checking for allowed use</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html#use-multiple-ai-tools"><i class="fa fa-check"></i>Use Multiple AI Tools</a>
<ul>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html#tips-for-using-multiple-ai-tools"><i class="fa fa-check"></i>Tips for using multiple AI tools</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html#educate-yourself-and-others"><i class="fa fa-check"></i>Educate Yourself and Others</a>
<ul>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html#tips-to-educate-yourself-and-others"><i class="fa fa-check"></i>Tips to educate yourself and others</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="adherence-practices.html"><a href="adherence-practices.html#summary-5"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="consent-and-ai.html"><a href="consent-and-ai.html"><i class="fa fa-check"></i>Consent and AI</a>
<ul>
<li class="chapter" data-level="" data-path="consent-and-ai.html"><a href="consent-and-ai.html#tips-to-encourage-responsible-consent-practices"><i class="fa fa-check"></i>Tips to encourage responsible consent practices</a></li>
<li class="chapter" data-level="" data-path="consent-and-ai.html"><a href="consent-and-ai.html#summary-6"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html"><i class="fa fa-check"></i>IDARE and AI</a>
<ul>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html#ai-is-biased"><i class="fa fa-check"></i>AI is biased</a></li>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html#examples-of-ai-bias"><i class="fa fa-check"></i>Examples of AI Bias</a>
<ul>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html#amazons-resume-system-was-biased-against-women"><i class="fa fa-check"></i>Amazon’s resume system was biased against women</a></li>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html#x-ray-studies-show-ai-surprises"><i class="fa fa-check"></i>X-ray studies show AI surprises</a></li>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html#tips-for-mitigating-bias"><i class="fa fa-check"></i>Tips for Mitigating Bias</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html#be-extremely-careful-using-ai-for-decisions"><i class="fa fa-check"></i>Be extremely careful using AI for decisions</a></li>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html#more-inclusive-teams-means-better-models"><i class="fa fa-check"></i>More inclusive teams means better models</a></li>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html#access"><i class="fa fa-check"></i>Access</a></li>
<li class="chapter" data-level="" data-path="idare-and-ai.html"><a href="idare-and-ai.html#summary-7"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html"><i class="fa fa-check"></i>Ethical process</a>
<ul>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#ethical-use-process"><i class="fa fa-check"></i>Ethical Use Process</a>
<ul>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#reflection-during-inception-of-the-idea"><i class="fa fa-check"></i>Reflection during inception of the idea</a></li>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#reflection-during-use"><i class="fa fa-check"></i>Reflection during use</a></li>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#reflection-after-use"><i class="fa fa-check"></i>Reflection after use</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#ethical-development-process"><i class="fa fa-check"></i>Ethical Development Process</a>
<ul>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#reflection-during-inception-of-the-idea-1"><i class="fa fa-check"></i>Reflection during inception of the idea</a></li>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#planning-reflections"><i class="fa fa-check"></i>Planning Reflections</a></li>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#development-reflection"><i class="fa fa-check"></i>Development Reflection</a></li>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#post-development-reflection"><i class="fa fa-check"></i>Post-development Reflection</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ethical-process.html"><a href="ethical-process.html#summary-8"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="part"><span><b>Determining AI Needs</b></span></li>
<li class="chapter" data-level="" data-path="introduction-to-determining-ai-needs.html"><a href="introduction-to-determining-ai-needs.html"><i class="fa fa-check"></i>Introduction to Determining AI Needs</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-determining-ai-needs.html"><a href="introduction-to-determining-ai-needs.html#motivation-3"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="" data-path="introduction-to-determining-ai-needs.html"><a href="introduction-to-determining-ai-needs.html#target-audience-3"><i class="fa fa-check"></i>Target Audience</a></li>
<li class="chapter" data-level="" data-path="introduction-to-determining-ai-needs.html"><a href="introduction-to-determining-ai-needs.html#curriculum-2"><i class="fa fa-check"></i>Curriculum</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-are-the-components-of-ai.html"><a href="what-are-the-components-of-ai.html"><i class="fa fa-check"></i>What are the components of AI?</a>
<ul>
<li class="chapter" data-level="" data-path="what-are-the-components-of-ai.html"><a href="what-are-the-components-of-ai.html#learning-objectives-2"><i class="fa fa-check"></i>Learning objectives:</a></li>
<li class="chapter" data-level="" data-path="what-are-the-components-of-ai.html"><a href="what-are-the-components-of-ai.html#intro"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="" data-path="what-are-the-components-of-ai.html"><a href="what-are-the-components-of-ai.html#what-makes-an-ai-model-accurate"><i class="fa fa-check"></i>What makes an AI model accurate?</a></li>
<li class="chapter" data-level="" data-path="what-are-the-components-of-ai.html"><a href="what-are-the-components-of-ai.html#what-makes-an-ai-model-efficient"><i class="fa fa-check"></i>What makes an AI model efficient?</a></li>
<li class="chapter" data-level="" data-path="what-are-the-components-of-ai.html"><a href="what-are-the-components-of-ai.html#putting-it-together"><i class="fa fa-check"></i>Putting it together</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html"><i class="fa fa-check"></i>Determining your AI needs</a>
<ul>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#learning-objectives-3"><i class="fa fa-check"></i>Learning objectives:</a></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#intro-1"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#generalized-custom-ai-use-cases"><i class="fa fa-check"></i>Generalized Custom AI Use Cases</a>
<ul>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#customized-knowledge"><i class="fa fa-check"></i>Customized Knowledge</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#customized-security"><i class="fa fa-check"></i>Customized Security</a></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#customized-interface"><i class="fa fa-check"></i>Customized Interface</a>
<ul>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#generalized-strategies-for-these-needs"><i class="fa fa-check"></i>Generalized strategies for these needs</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#the-whole-picture"><i class="fa fa-check"></i>The Whole Picture</a>
<ul>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#technical-expertise-needs"><i class="fa fa-check"></i>Technical expertise needs</a></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#funding-needs"><i class="fa fa-check"></i>Funding needs</a></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#time-needs"><i class="fa fa-check"></i>Time needs</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#example-project-strategies"><i class="fa fa-check"></i>Example project strategies</a>
<ul>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#cogniflow-example"><i class="fa fa-check"></i>Cogniflow example</a></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#privateai"><i class="fa fa-check"></i>PrivateAI</a></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#chatgpt-api"><i class="fa fa-check"></i>ChatGPT API</a></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#hugging-face"><i class="fa fa-check"></i>Hugging Face</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="determining-your-ai-needs.html"><a href="determining-your-ai-needs.html#conclusion"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="customized-knowledge-for-ai.html"><a href="customized-knowledge-for-ai.html"><i class="fa fa-check"></i>Customized Knowledge for AI</a>
<ul>
<li class="chapter" data-level="" data-path="customized-knowledge-for-ai.html"><a href="customized-knowledge-for-ai.html#learning-objectives-4"><i class="fa fa-check"></i>Learning objectives:</a></li>
<li class="chapter" data-level="" data-path="customized-knowledge-for-ai.html"><a href="customized-knowledge-for-ai.html#intro-2"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="" data-path="customized-knowledge-for-ai.html"><a href="customized-knowledge-for-ai.html#summary-of-possible-strategies"><i class="fa fa-check"></i>Summary of possible strategies</a>
<ul>
<li class="chapter" data-level="" data-path="customized-knowledge-for-ai.html"><a href="customized-knowledge-for-ai.html#prompt-engineering"><i class="fa fa-check"></i>Prompt engineering</a></li>
<li class="chapter" data-level="" data-path="customized-knowledge-for-ai.html"><a href="customized-knowledge-for-ai.html#prompt-tuning-or-p-tuning"><i class="fa fa-check"></i>Prompt tuning or “P-tuning”</a></li>
<li class="chapter" data-level="" data-path="customized-knowledge-for-ai.html"><a href="customized-knowledge-for-ai.html#fine-tuning"><i class="fa fa-check"></i>Fine Tuning</a></li>
<li class="chapter" data-level="" data-path="customized-knowledge-for-ai.html"><a href="customized-knowledge-for-ai.html#find-a-base-model-to-start-with"><i class="fa fa-check"></i>Find a base model to start with</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="customized-knowledge-for-ai.html"><a href="customized-knowledge-for-ai.html#example-strategies-for-fine-tuning"><i class="fa fa-check"></i>Example strategies for Fine tuning</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html"><i class="fa fa-check"></i>Customized Security for AI</a>
<ul>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#learning-objectives-5"><i class="fa fa-check"></i>Learning objectives:</a></li>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#intro-3"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#data-security-basics"><i class="fa fa-check"></i>Data security basics</a></li>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#secure-ai-solutions-for-protected-data"><i class="fa fa-check"></i>Secure AI solutions for protected data</a></li>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#data-obscuring-techniques"><i class="fa fa-check"></i>Data obscuring techniques</a></li>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#example-security-customization-strategies"><i class="fa fa-check"></i>Example Security Customization strategies</a>
<ul>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#privateai-1"><i class="fa fa-check"></i>PrivateAI</a></li>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#deidentify"><i class="fa fa-check"></i>deidentify</a></li>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#aws-servers-huggingface"><i class="fa fa-check"></i>AWS servers + HuggingFace</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="customized-security-for-ai.html"><a href="customized-security-for-ai.html#always-double-triple-quadruple-check"><i class="fa fa-check"></i>Always double, triple, quadruple, check</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="customized-interfaces-for-ai.html"><a href="customized-interfaces-for-ai.html"><i class="fa fa-check"></i>Customized Interfaces for AI</a>
<ul>
<li class="chapter" data-level="" data-path="customized-interfaces-for-ai.html"><a href="customized-interfaces-for-ai.html#learning-objectives-6"><i class="fa fa-check"></i>Learning objectives:</a></li>
<li class="chapter" data-level="" data-path="customized-interfaces-for-ai.html"><a href="customized-interfaces-for-ai.html#intro-4"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="" data-path="customized-interfaces-for-ai.html"><a href="customized-interfaces-for-ai.html#general-strategies-for-custom-interfaces"><i class="fa fa-check"></i>General strategies for custom interfaces</a></li>
<li class="chapter" data-level="" data-path="customized-interfaces-for-ai.html"><a href="customized-interfaces-for-ai.html#examples-of-ai-customized-interface-strategies"><i class="fa fa-check"></i>Examples of AI customized interface strategies</a></li>
<li class="chapter" data-level="" data-path="customized-interfaces-for-ai.html"><a href="customized-interfaces-for-ai.html#premade-ai-tools"><i class="fa fa-check"></i>Premade AI tools</a></li>
<li class="chapter" data-level="" data-path="customized-interfaces-for-ai.html"><a href="customized-interfaces-for-ai.html#ai-tool-apis"><i class="fa fa-check"></i>AI tool APIs</a></li>
<li class="chapter" data-level="" data-path="customized-interfaces-for-ai.html"><a href="customized-interfaces-for-ai.html#custom-builds"><i class="fa fa-check"></i>Custom builds</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="evaluating-your-customized-ai-tool.html"><a href="evaluating-your-customized-ai-tool.html"><i class="fa fa-check"></i>Evaluating your customized AI tool</a>
<ul>
<li class="chapter" data-level="" data-path="evaluating-your-customized-ai-tool.html"><a href="evaluating-your-customized-ai-tool.html#learning-objectives-7"><i class="fa fa-check"></i>Learning objectives:</a></li>
<li class="chapter" data-level="" data-path="evaluating-your-customized-ai-tool.html"><a href="evaluating-your-customized-ai-tool.html#intro-5"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="" data-path="evaluating-your-customized-ai-tool.html"><a href="evaluating-your-customized-ai-tool.html#evaluating-accuracy-of-an-ai-model"><i class="fa fa-check"></i>Evaluating Accuracy of an AI model</a></li>
<li class="chapter" data-level="" data-path="evaluating-your-customized-ai-tool.html"><a href="evaluating-your-customized-ai-tool.html#evaluating-computational-efficiency-of-an-ai-model"><i class="fa fa-check"></i>Evaluating Computational Efficiency of an AI model</a></li>
<li class="chapter" data-level="" data-path="evaluating-your-customized-ai-tool.html"><a href="evaluating-your-customized-ai-tool.html#evaluating-usability-of-an-ai-model"><i class="fa fa-check"></i>Evaluating Usability of an AI model</a></li>
</ul></li>
<li class="part"><span><b>Developing AI Policy</b></span></li>
<li class="chapter" data-level="" data-path="introduction-to-developing-ai-policy.html"><a href="introduction-to-developing-ai-policy.html"><i class="fa fa-check"></i>Introduction to Developing AI Policy</a>
<ul>
<li class="chapter" data-level="" data-path="introduction-to-developing-ai-policy.html"><a href="introduction-to-developing-ai-policy.html#motivation-4"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="" data-path="introduction-to-developing-ai-policy.html"><a href="introduction-to-developing-ai-policy.html#target-audience-4"><i class="fa fa-check"></i>Target Audience</a></li>
<li class="chapter" data-level="" data-path="introduction-to-developing-ai-policy.html"><a href="introduction-to-developing-ai-policy.html#curriculum-3"><i class="fa fa-check"></i>Curriculum</a></li>
<li class="chapter" data-level="" data-path="introduction-to-developing-ai-policy.html"><a href="introduction-to-developing-ai-policy.html#learning-objectives-8"><i class="fa fa-check"></i>Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="why-do-i-need-an-ai-policy.html"><a href="why-do-i-need-an-ai-policy.html"><i class="fa fa-check"></i>Why do I need an AI policy?</a></li>
<li class="chapter" data-level="" data-path="elements-of-an-ai-policy.html"><a href="elements-of-an-ai-policy.html"><i class="fa fa-check"></i>Elements of an AI policy</a></li>
<li class="chapter" data-level="" data-path="building-an-ai-advisory-team.html"><a href="building-an-ai-advisory-team.html"><i class="fa fa-check"></i>Building an AI advisory team</a></li>
<li class="chapter" data-level="" data-path="considerations-for-creating-an-ai-policy.html"><a href="considerations-for-creating-an-ai-policy.html"><i class="fa fa-check"></i>Considerations for creating an AI Policy</a>
<ul>
<li class="chapter" data-level="" data-path="considerations-for-creating-an-ai-policy.html"><a href="considerations-for-creating-an-ai-policy.html#an-ai-policy-alone-is-not-enough"><i class="fa fa-check"></i>An AI policy alone is not enough</a></li>
<li class="chapter" data-level="" data-path="considerations-for-creating-an-ai-policy.html"><a href="considerations-for-creating-an-ai-policy.html#get-lots-of-voices-weighing-in-from-the-beginning"><i class="fa fa-check"></i>Get lots of voices weighing in from the beginning</a></li>
<li class="chapter" data-level="" data-path="considerations-for-creating-an-ai-policy.html"><a href="considerations-for-creating-an-ai-policy.html#consider-how-to-keep-your-guidance-agile"><i class="fa fa-check"></i>Consider how to keep your guidance agile</a></li>
<li class="chapter" data-level="" data-path="considerations-for-creating-an-ai-policy.html"><a href="considerations-for-creating-an-ai-policy.html#make-it-easy-for-people-to-follow-your-policy-through-effective-training"><i class="fa fa-check"></i>Make it easy for people to follow your policy through effective training</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ai-acts-orders-and-regulations.html"><a href="ai-acts-orders-and-regulations.html"><i class="fa fa-check"></i>AI acts, orders, and regulations</a>
<ul>
<li class="chapter" data-level="" data-path="ai-acts-orders-and-regulations.html"><a href="ai-acts-orders-and-regulations.html#the-eu-ai-act"><i class="fa fa-check"></i>The EU AI Act</a></li>
<li class="chapter" data-level="" data-path="ai-acts-orders-and-regulations.html"><a href="ai-acts-orders-and-regulations.html#industry-specific-policies"><i class="fa fa-check"></i>Industry-specific policies</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="case-studies.html"><a href="case-studies.html"><i class="fa fa-check"></i>Case Studies</a>
<ul>
<li class="chapter" data-level="" data-path="case-studies.html"><a href="case-studies.html#education"><i class="fa fa-check"></i>Education</a></li>
<li class="chapter" data-level="" data-path="case-studies.html"><a href="case-studies.html#healthcare"><i class="fa fa-check"></i>Healthcare</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="other-laws-to-consider.html"><a href="other-laws-to-consider.html"><i class="fa fa-check"></i>Other laws to consider</a>
<ul>
<li class="chapter" data-level="" data-path="other-laws-to-consider.html"><a href="other-laws-to-consider.html#intellectual-property"><i class="fa fa-check"></i>Intellectual Property</a></li>
<li class="chapter" data-level="" data-path="other-laws-to-consider.html"><a href="other-laws-to-consider.html#data-privacy-and-information-security"><i class="fa fa-check"></i>Data Privacy and Information Security</a></li>
<li class="chapter" data-level="" data-path="other-laws-to-consider.html"><a href="other-laws-to-consider.html#liability"><i class="fa fa-check"></i>Liability</a></li>
<li class="chapter" data-level="" data-path="other-laws-to-consider.html"><a href="other-laws-to-consider.html#who-can-tell-you-about-your-particular-legal-concerns"><i class="fa fa-check"></i>Who can tell you about your particular legal concerns</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<p style="text-align:center;"> <a href="https://github.com/jhudsl/OTTR_Template" target="blank" > This content was published with</a> <a href="https://bookdown.org/" target="blank"> bookdown by: </a> </p>
<p style="text-align:center;"> <a href="https://hutchdatascience.org/"> The Fred Hutch Data Science Lab </a></p>
<p style="text-align:center; font-size: 12px;"> <a href="https://github.com/rstudio4edu/rstudio4edu-book/"> Style adapted from: rstudio4edu-book </a> <a href ="https://creativecommons.org/licenses/by/2.0/"> (CC-BY 2.0) </a></p>
<p style="padding-left: 40px;"><div class="trapezoid" style = "padding-left: 40px;"><span>  <a href="https://forms.gle/W6Mg4rzuMK6Yk3Am8"> Click here to provide feedback</a> <img src="assets/itcr_arrow.png" style=" width: 10%" ></span></div></p>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">AI for Decision Makers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<head>
  <meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=10.0,initial-scale=1.0">
  <!--script src="https://kit.fontawesome.com/6a26f47516.js"></script-->
  <!--<script src="assets/hideOutput.js"></script>-->
  <link href="assets/style.css" rel="stylesheet">
</head>
        


<div class="hero-image-container"> 
  <img class= "hero-image" src="assets/dasl_thin_main_image.png">
</div>
<div id="societal-impact" class="section level1 hasAnchor">
<h1>Societal Impact<a href="societal-impact.html#societal-impact" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>There is the potential for AI to dramatically influence society. It is our responsibility to proactively think about what uses and impacts we consider to be useful and appropriate and those we consider harmful and inappropriate.</p>
<div class="disclaimer">
<p><strong>Disclaimer:</strong> The thoughts and ideas presented in this course are not to be substituted for legal or ethical advice and are only meant to give you a starting point for gathering information about AI policy and regulations to consider.</p>
</div>
<div id="guidelines-for-responsible-development-and-use-of-ai." class="section level2 hasAnchor">
<h2>Guidelines for Responsible Development and Use of AI.<a href="societal-impact.html#guidelines-for-responsible-development-and-use-of-ai." class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are currently several guidelines for the responsible use and development of AI:</p>
<ul>
<li>United States <a href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/">Blueprint for an AI Bill of Rights</a></li>
<li>United States <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/">Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence</a></li>
<li><a href="https://www.nist.gov/itl/ai-risk-management-framework">United States National Institute of Standards and Technology (NIST): AI Risk Management Framework</a></li>
<li>European Commission <a href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai">Ethics Guidelines for trustworthy AI</a></li>
<li><a href="https://artificialintelligenceact.eu/the-act/">European Union AI Act</a></li>
<li><a href="https://www.gov.uk/government/publications/national-ai-strategy">United Kingdom National AI Strategy</a></li>
<li>The Institute of Electrical and Electronics Engineers (IEEE) <a href="https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v2.pdf">Ethically Aligned Design Version 2</a></li>
</ul>
<p>As this is an emerging technology, more guidelines will be developed and updated as the technology evolves. When you read this, more guideline and updates are likely to be available. It is important to be aware of the current ethical guidelines and regulations for your respective field.</p>
<p><img src="resources/images/02b-Avoiding_Harm-concepts_files/figure-html/1L6-8DWn028c1o0p9gwXmz90BRcy_PjPqb683nbk1gHQ_g2aaead717c1_8_0.png" alt="A cartoon of a robot reading'." width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="major-ethical-considerations" class="section level2 hasAnchor">
<h2>Major Ethical Considerations<a href="societal-impact.html#major-ethical-considerations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter we will discuss the some of the major ethical considerations in terms of possible societal consequences for the use or development of AI tools:</p>
<ol style="list-style-type: decimal">
<li><strong>Intentional and Inadvertent Harm</strong> - Data and technology intended to serve one purpose may be reused by others for unintended purposes. How do we prevent intentional harm?</li>
<li><strong>Replacing Humans</strong> - AI tools can help humans, but they are not a replacement. Humans are still much better at generalizing their knowledge to other contexts (<span class="citation">Sinz et al. (<a href="#ref-sinz_engineering_2019">2019</a>)</span>). Also studies suggests that humans value content and objects created by humans more than that of AI when it relates to abstract thought or unique work (<span class="citation">Bellaiche et al. (<a href="#ref-bellaiche_humans_2023">2023</a>)</span>, <span class="citation">Granulo, Fuchs, and Puntoni (<a href="#ref-granulo_preference_2021">2021</a>)</span>).</li>
<li><strong>Inappropriate Use and Lack of Oversight</strong> - There are situations in which using AI might not be appropriate now or in the future. A lack of human monitoring and oversight can result in harm.</li>
<li><strong>Bias Perpetuation and Disparities</strong> - AI models are built on data and code that were created by biased humans, thus bias can be further perpetuated by using AI tools. In some cases bias can even be exaggerated. This combined with differences in access may exacerbate disparities.</li>
<li><strong>Security and Privacy Issues</strong> - Data for AI systems should be collected in an ethical manner that is mindful of the rights of the individuals the data comes from. Data around usage of those tools should also be collected in an ethical manner. Commercial tool usage with proprietary or private data, code, text, images or other files may result in leaked data not only to the developers of the commercial tool, but potentially also to other users.</li>
<li><strong>Climate Impact</strong> - As we continue to use more and more data and computing power, we need to be ever more mindful of how we generate the electricity to store and perform our computations.</li>
<li><strong>Transparency</strong> - Being transparent about what AI tools you use where possible, helps others to better understand how you made decisions or created any content that was derived by AI, as well as the possible sources that the AI tools might have used when helping you. It may also help with future unknown issues related to the use of these tools.</li>
</ol>
<div class="ethics">
<p>Keep in mind that some fields, organizations, and societies have guidelines or requirements for using AI, like for example the policy for the use of large language models for the <a href="https://www.iscb.org/iscb-policy-statements/iscb-policy-for-acceptable-use-of-large-language-models">International Society for Computational Biology</a>. Be aware of the requirements/guidelines for your field.</p>
</div>
<p>Note that this is an incomplete list; additional ethical concerns will become apparent as we continue to use these new technologies. We highly suggest that users of these tools be <strong>careful to learn more about the specific tools they are interested in</strong> and to be <strong>transparent</strong> about the use of these tools, so that as new ethical issues emerge, we will be better prepared to understand the implications.</p>
</div>
<div id="intentional-and-inadvertent-harm" class="section level2 hasAnchor">
<h2>Intentional and Inadvertent Harm<a href="societal-impact.html#intentional-and-inadvertent-harm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>AI tools need to be developed with safeguards and continually audited to ensure that the AI system is not responsive to harmful requests by users. With additional usage and updates, AI tools can adapt and thus continual auditing is required.</p>
<p>Of course using AI to help you perform a harmful action would result in intentional harm. This may sound like an obvious and easy issue to avoid, at least by those with good intent. However, the consequences may be much further reaching than might be first anticipated.</p>
<p>Perhaps you or your company develop an AI tool that helps to identify individuals that might especially benefit from a product or service that you offer. This in and of itself is likely not harmful. However, the data you have used, the data that you may have collected, and the tool that you have created, all could be used for other malicious reasons, such as targeting specific groups of people for advertisements when they are vulnerable.</p>
<p>Therefore it is critical that we be considerate of the downstream consequences of what we create and what might happen if that technology or data was used for other purposes.</p>
<p><img src="resources/images/02b-Avoiding_Harm-concepts_files/figure-html/1L6-8DWn028c1o0p9gwXmz90BRcy_PjPqb683nbk1gHQ_g2aaead717c1_8_6.png" alt="A robot thinking'." width="100%" style="display: block; margin: auto;" /></p>
<div id="tips-for-avoiding-inadvertent-harm" class="section level3 hasAnchor">
<h3>Tips for avoiding inadvertent harm<a href="societal-impact.html#tips-for-avoiding-inadvertent-harm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="foruse">
<p><strong>For decision makers about AI use:</strong></p>
<ul>
<li>Consider how the content or decisions generated by an AI tool might be used by others.</li>
<li>Continually audit how AI tools that you are using are preforming.</li>
<li>Do not implement changes to systems or make important decisions using AI tools without AI oversight.</li>
</ul>
</div>
<div class="fordev">
<p><strong>For decision makers about AI development:</strong></p>
<ul>
<li>Consider how newly developed AI tools might be used by others.</li>
<li>Continually audit AI tools to look for unexpected and potentially harmful or biased behavior.</li>
<li>Be transparent with users about the limitations of the tool and the data used to train the tool.</li>
<li>Caution potential users about any potential negative consequences of use</li>
</ul>
</div>
</div>
</div>
<div id="replacing-humans" class="section level2 hasAnchor">
<h2>Replacing Humans<a href="societal-impact.html#replacing-humans" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>While AI systems are useful, they <strong>do not replace human strengths</strong>. While AI systems are good at synthesizing lots of data, humans remain far superior at generalizing concepts to new contexts (<span class="citation">Sinz et al. (<a href="#ref-sinz_engineering_2019">2019</a>)</span>).</p>
<p>AI systems should be thought of as better computers as opposed to replacements for humans.</p>
<p><img src="resources/images/02b-Avoiding_Harm-concepts_files/figure-html/1L6-8DWn028c1o0p9gwXmz90BRcy_PjPqb683nbk1gHQ_g2aaead717c1_8_69.png" alt="A small robot on a computer'." width="100%" style="display: block; margin: auto;" /></p>
<p>While there are some contexts in which human labor has already been replaced by robotics and AI, studies show that humans tend to prefer human-made goods when those goods are not strictly functional (<span class="citation">Bellaiche et al. (<a href="#ref-bellaiche_humans_2023">2023</a>)</span>, <span class="citation">Granulo, Fuchs, and Puntoni (<a href="#ref-granulo_preference_2021">2021</a>)</span>).
It has been proposed that there will be radical shifts in the way that humans work in many fields including health care, banking, retail, security, and more (<span class="citation">Selenko et al. (<a href="#ref-selenko_artificial_2022">2022</a>)</span>). Yet we need to implement changes gradually to allow for time to better understand the consequences and mindfully consider how such changes impact human employment and well-being.</p>
<p><span class="citation">Selenko et al. (<a href="#ref-selenko_artificial_2022">2022</a>)</span> have proposed a <a href="https://journals.sagepub.com/doi/full/10.1177/09637214221091823">framework</a> for considering the impact of AI usage on human workers to promote benefit and avoid harm. It suggests considering usage in a few different ways: AI for complementing work, AI for replacing tasks, and AI for generating new tasks. It suggests considering how such usages might reduce tedious or dangerous work, while also preserving work-related benefits such as self-esteem, belonging, and perceived meaningfulness. See <a href="https://journals.sagepub.com/doi/full/10.1177/09637214221091823">here</a> for the article.</p>
<div class="example">
<p><span id="exm:unlabeled-div-1" class="example"><strong>Example 1  </strong></span>AI might become much more prominent in the <strong>field of journalism</strong> and may help deliver more rapidly, deliver news from dangerous locations, and possibly even create content less biased politically or otherwise if the models are specifically trained to be objective (<span class="citation">Latar (<a href="#ref-latar_robot_2015">2015</a>)</span>). Yet, larger usage of AI in journalism also poses additional risks of misinformation, infiltration by outsiders, and a lack of human values if the usage lacks appropriate and sufficient human oversight.</p>
<blockquote>
<p>“robot journalist story writers will have instant
access to new insights and information, and their new ability to compose the story and publish it in seconds may cause human journalists to become obsolete. This is
alarming, as no robot journalists can replace human journalists as the guardians of
democracy and human rights.” (<span class="citation">Latar (<a href="#ref-latar_robot_2015">2015</a>)</span>)</p>
</blockquote>
<blockquote>
<p>“This potential threat to the profession of human journalism is viewed by some
optimistic journalists merely as another tool that will free them of the necessity to
conduct costly and, at times, dangerous investigations. The robot journalists will
provide them, so the optimists hope, with an automated draft for a story that they will edit and enrich with their in-depth analysis, their perspectives and their narrative talents.</p>
</blockquote>
<blockquote>
<p>The more pessimistic journalists view the new robot journalists as a real threat
to their livelihood and style of working and living.</p>
</blockquote>
</div>
<p>Computer science is a field that has historically lacked diversity. It is also critical that we support diverse new learners of computer science, as we will continue to need human involvement in the development and use of AI tools. This can help to ensure that more diverse perspectives are accounted for in our understanding of how these tools should be used responsibly.</p>
<div id="tips-for-supporting-human-contributions" class="section level3 hasAnchor">
<h3>Tips for supporting human contributions<a href="societal-impact.html#tips-for-supporting-human-contributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="foruse">
<p><strong>For decision makers about AI use:</strong></p>
<ul>
<li>Avoid thinking that content by AI tools must be better than that created by humans, as this is not true (<span class="citation">Sinz et al. (<a href="#ref-sinz_engineering_2019">2019</a>)</span>).</li>
<li>Recall that humans wrote the code to create these AI tools and that the data used to train these AI tools also came from humans. Many of the large commercial AI tools were trained on websites and other content from the internet.</li>
<li>Be transparent where possible about <strong>when you do or do not use AI tools</strong>, give credit to the humans involved as much as possible.</li>
<li>Make decisions about using AI tools based on ethical <a href="https://journals.sagepub.com/doi/full/10.1177/09637214221091823">frameworks</a> in terms of considering the impact on human workers.</li>
</ul>
</div>
<p><br></p>
<div class="fordev">
<p><strong>For decision makers about AI development:</strong></p>
<ul>
<li>Be transparent about the data used to generate tools as much as possible and provide information about what humans may have been involved in the creation of the data.</li>
<li>Make decisions about creating AI tools based on ethical <a href="https://journals.sagepub.com/doi/full/10.1177/09637214221091823">frameworks</a> in terms of considering the impact on human workers.</li>
</ul>
</div>
<p><br></p>
<div class="ethics">
<p>A new term in the medical field called <a href="https://www.technologyreview.com/2023/04/21/1071921/ai-is-infiltrating-health-care-we-shouldnt-let-it-make-decisions/">AI paternalism</a> describes the concept that doctors (and others) may trust AI over their own judgment or the experiences of the patients they treat. This has already been shown to be a problem with earlier AI systems intended to help distinguish patient groups. Not all humans will necessarily fit the expectations of the AI model if it is not very good at predicting edge cases <span class="citation">(<a href="#ref-AI_paternalism">Hamzelou n.d.</a>)</span>. Therefore, in all fields it is important for us to not forget our value as humans in our understanding of the world.</p>
</div>
</div>
</div>
<div id="inappropriate-use-and-lack-of-oversight" class="section level2 hasAnchor">
<h2>Inappropriate Use and Lack of Oversight<a href="societal-impact.html#inappropriate-use-and-lack-of-oversight" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are situations in which we may, as a society, not want an automated response. There may even be situations in which we do not want to bias our own human judgment by that of an AI system. There may be other situations where the efficiency of AI may also be considered inappropriate. While many of these topics are still under debate and AI technology continues to improve, we challenge the readers to consider such cases given what is currently possible and what may be possible in the future.</p>
<p>Some reasons why AI may not be appropriate for certain situation include:</p>
<ul>
<li>Despite the common misconception that AI systems have clearer judgment than humans, they are in fact typically just as prone to bias and sometimes even exacerbate bias (<span class="citation">Pethig and Kroenung (<a href="#ref-pethig_biased_2023">2023</a>)</span>). There are some very mindful researchers working on these issues in specific contexts and making progress where AI may actually improve on human judgment, but generally speaking AI systems are currently typically biased and reflective of human judgment but in a more limited manner based on the context in which they have been trained.</li>
<li>AI systems can behave in unexpected ways (<span class="citation">Gichoya et al. (<a href="#ref-gichoya_ai_2022">2022</a>)</span>).</li>
<li>Humans are still better than AI at generalizing what they learn for new contexts (<span class="citation">Sinz et al. (<a href="#ref-sinz_engineering_2019">2019</a>)</span>).</li>
<li>Humans can better understand the consequences of discussions from a humanity standpoint.</li>
</ul>
<p>Some examples where it may be considered inappropriate for AI systems to be used (even with human involvement) include:</p>
<ul>
<li>In the justice system to determine if someone is guilty of a crime or to determine the punishment of someone found guilty of a crime.</li>
<li>It may be considered inappropriate for AI systems to be used in certain warfare circumstances.</li>
</ul>
<p>Additionally there are many contexts in which using AI without human intervention could be very problematic including:</p>
<ul>
<li>Diagnosis of disease for patients - Delivering this news should likely come from a human. Secondly, the stakes for errors in the AI system could be very high. What if the system works poorly occasionally for certain individuals? What if the system starts behaving strangely? What if a patient with an unusual situation comes in that the AI system can’t work well for?</li>
</ul>
<p>Even for seemingly benign uses, if humans do not intervene, it is possible that negative consequences could occur if the system starts working poorly or unusually.</p>
<div class="example">
<p><span id="exm:unlabeled-div-2" class="example"><strong>Example 2  </strong></span><strong>Real-World Example</strong></p>
<p>Uber drivers in India experienced issues with the facial recognition technology for logging into the App. This caused many drivers to get locked out of their accounts temporarily or permanently resulting in a reduction in their capacity to work and earn a living (<span class="citation">Bansal (<a href="#ref-bansal_ubers_2022">2022</a>)</span>).</p>
<p>Read more about this in this <a href="https://www.technologyreview.com/2022/12/06/1064287/ubers-facial-recognition-is-locking-indian-drivers-out-of-their-accounts/">article</a>.</p>
</div>
<div id="tips-for-avoiding-inappropriate-uses-and-lack-of-oversight" class="section level3 hasAnchor">
<h3>Tips for avoiding inappropriate uses and lack of oversight<a href="societal-impact.html#tips-for-avoiding-inappropriate-uses-and-lack-of-oversight" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="foruse">
<p><strong>For decision makers about AI use:</strong></p>
<ul>
<li>Stay up-to-date on current laws, practices, and standards for your field, especially for high-risk uses.</li>
<li>Stay up-to-date on the news for how others have experienced their use of AI.</li>
<li>Stay involved in discussions about appropriate uses for AI, particularly for policy.</li>
<li>Begin using AI slowly and iteratively to allow time to determine the appropriateness of the use. Some issues will only be discovered after some experience.</li>
<li>Involve a diverse group of individuals in discussions of intended uses to better account for a variety of perspectives.</li>
<li>Seek outside expert opinion whenever you are unsure about your AI use plans.</li>
<li>Consider AI alternatives if something doesn’t feel right.</li>
</ul>
</div>
<div class="fordev">
<p><strong>For decision makers about AI development:</strong></p>
<ul>
<li>Be transparent with users about the potential risks that usage may cause.</li>
<li>Stay up-to-date on current laws, practices, and standards for your field, especially for high-risk uses.</li>
<li>Stay up-to-date on the news for how others may have experienced problems using AI.</li>
<li>Stay involved in discussions about appropriate uses for AI, particularly for policy.</li>
<li>Involve a diverse group of individuals in development to better account for a variety of perspectives.</li>
<li>Seek outside expert opinion whenever you are unsure about your AI development plans.</li>
<li>Consider AI alternatives if something doesn’t feel right.</li>
<li>Design tools with safeguards to stop users from requesting harmful or irresponsible uses.</li>
<li>Design tools with responses that may ask users to be more considerate in the usage of the tool.</li>
</ul>
</div>
</div>
</div>
<div id="bias-perpetuation-and-disparities" class="section level2 hasAnchor">
<h2>Bias Perpetuation and Disparities<a href="societal-impact.html#bias-perpetuation-and-disparities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One of the biggest concerns is the potential for AI to further perpetuate bias. AI systems are trained on data created by humans. If this data used to train the system is biased (and this includes existing code that may be written in a biased manner), the resulting content from the AI tools could also be biased. This could lead to discrimination, abuse, or neglect for certain groups of people, such as those with certain ethnic or cultural backgrounds, genders, ages, sexuality, capabilities, religions or other group affiliations.</p>
<p>It is well known that data and code are often biased <span class="citation">(<a href="#ref-belenguer_ai_2022">Belenguer 2022</a>)</span>. The resulting output of AI tools should be evaluated for bias and modified where needed. Please be aware that because bias is intrinsic, it may be difficult to identify issues. Therefore, people with specialized training to recognize bias should be consulted. It is also vital that evaluations be made throughout the software development process of new AI tools to check for and consider potential perpetuation of bias.</p>
<p>Because of differences in access to technology, disparities may be further exacerbated by the usage of AI tools. Consideration and support for under-served populations will be even more necessary. For example tools that only work well on individuals with light skin, will lead to further challenges to some individuals.</p>
<blockquote>
<p>Developing and scaling-up artificial intelligence-based innovations for use in low- and middle-income countries will thus require deliberate efforts to generate locally representative training data (<span class="citation">Paul and Schaefer (<a href="#ref-paul_safeguards_2020">2020</a>)</span>).</p>
</blockquote>
<p>In the flip side, AI has the potential if used wisely, to reduce health inequities by potentially enabling the scaling and access to expertise not yet available in some locations.</p>
<div id="tips-for-avoiding-bias" class="section level3 hasAnchor">
<h3>Tips for avoiding bias<a href="societal-impact.html#tips-for-avoiding-bias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="foruse">
<p><strong>For decision makers about AI use:</strong></p>
<ul>
<li>Be aware of the biases in the data that is used to train AI systems.</li>
<li>Check what data was used to train the AI tools that you use where possible. Tools that are more transparent are likely more ethically developed.</li>
<li>Check if the developers of the AI tools you are using were/are considerate of bias issues in their development where possible. Tools that are more transparent are likely more ethically developed.</li>
<li>Consider the possible outcomes of the use of content created by AI tools. Consider if the content could possibly be used in a manner that will result in discrimination.</li>
</ul>
</div>
<p><br></p>
<div class="fordev">
<p><strong>For decision makers about AI development:</strong></p>
<ul>
<li>Check for possible biases within data used to train new AI tools.
<ul>
<li>Are there harmful data values? Examples could include discriminatory and false associations.</li>
<li>Are the data adequately inclusive? Examples could include a lack of data about certain ethnic or gender groups or disabled individuals, which could result in code that does not adequately consider these groups, ignores them all together, or makes false associations.</li>
<li>Are the data of high enough quality? Examples could include data that is false about certain individuals.</li>
</ul></li>
<li>Evaluate the code for new AI tools for biases as it is developed. Check if any of the criteria for weighting certain data values over others are rooted in bias.</li>
<li>Continually audit the code for potentially biased responses. Potentially seek expert help.</li>
<li>Be transparent with users about potential bias risks.</li>
<li>Consider the possible outcomes of the use of content created by newly developed AI tools. Consider if the content could possibly be used in a manner that will result in discrimination.</li>
</ul>
</div>
<p>See <span class="citation">Belenguer (<a href="#ref-belenguer_ai_2022">2022</a>)</span> for more guidance. We also encourage you to check out <a href="https://www.youtube.com/embed/TWWsW1w-BVo?si=YLGbpVKrUz5b56vM">this video for a classic example of bias in AI</a>.</p>
<p>For further details check out this <a href="https://www.coursera.org/learn/algorithmic-fairness">course</a> on Coursera about building fair algorithms. We will also describe more in the next section.</p>
</div>
</div>
<div id="security-and-privacy-issues" class="section level2 hasAnchor">
<h2>Security and Privacy Issues<a href="societal-impact.html#security-and-privacy-issues" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Security and privacy are a major concern for AI usage. Here we discuss a few aspects related to this.</p>
<p><img src="resources/images/02b-Avoiding_Harm-concepts_files/figure-html/1L6-8DWn028c1o0p9gwXmz90BRcy_PjPqb683nbk1gHQ_g2aaead717c1_8_83.png" alt="Image of a robot at a door'." width="100%" style="display: block; margin: auto;" /></p>
<div id="use-the-right-tool-for-the-job" class="section level3 hasAnchor">
<h3>Use the right tool for the job<a href="societal-impact.html#use-the-right-tool-for-the-job" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are three kinds of commercial AI tools (<span class="citation">Nigro (<a href="#ref-nigro_ai_nodate">2023</a>)</span>):</p>
<ul>
<li>Consumer tools (likely not private/secure)</li>
<li>Enterprise tools (can be secure with the right legal agreements in place)</li>
<li>Open source tools (depends on where you use them and whether you control the computers they run on)</li>
</ul>
<p>Public commercial AI tools are often <strong>not designed to protect users from unknowingly submitting prompts that include propriety are private information</strong>. Different AI tools have different practices in terms of how they do or do not collect data about the prompts that people submit. They also have different practices in terms of if they reuse information from prompts to other users. Note that the AI system itself may not be trained on responses for how prompt data is collected or not. So asking the AI system may not give accurate answers.</p>
<div class="warning">
<p>Thus if users of public AI tools, such as ChatGPT submit prompts that include propriety or private information, they <strong>run the risk of that information being viewable not only by the developers/maintainers of the AI tool used, but also by other users</strong> who use that same AI tool.</p>
</div>
</div>
<div id="ai-can-have-security-blind-spots" class="section level3 hasAnchor">
<h3>AI can have security blind spots<a href="societal-impact.html#ai-can-have-security-blind-spots" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Furthermore, AI tools are not always trained in a way that is particularly conscious of data security. If for example, code is written using these tools by users who are less familiar with coding security concerns, protected data or important passwords may be leaked within the code itself. AI systems may also utilize data that was actually intended to be private.</p>
</div>
<div id="data-source-issues" class="section level3 hasAnchor">
<h3>Data source issues<a href="societal-impact.html#data-source-issues" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It is also important to consider what data the responses that you get from a commercial AI tool might actually be using. Are these datasets from people who consented to their data being used in this manner? If you are generating your own tools, did people consent for their data to be used as you intend?</p>
<p>Data privacy is a major issue all on it’s own:</p>
<blockquote>
<p>98% of Americans still feel they should have more control over the sharing of their data (<span class="citation">Pearce (<a href="#ref-pearce_beware_2021">2021</a>)</span>)</p>
</blockquote>
<p>It is important to follow legal and ethical guidance around the collection of data and to use tools that also abide by these guidelines.</p>
</div>
<div id="tips-for-reducing-security-and-privacy-issues" class="section level3 hasAnchor">
<h3>Tips for reducing security and privacy issues<a href="societal-impact.html#tips-for-reducing-security-and-privacy-issues" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="foruse">
<p><strong>For decision makers about AI use:</strong></p>
<ul>
<li>Check that no sensitive data, such as Personal Identifiable Information (PII) or propriety information becomes public through prompts to consumer AI systems or systems not designed or set up with the right legal agreements in place for sensitive data.</li>
<li>Consider purchasing a license for a private AI system if needed or create your own if you wish to work with sensitive data (seek expert guidance to determine if the AI systems are secure enough).</li>
<li>Ask AI tools for help with security when using consumer tools, but to not rely on them alone. In some cases, consumer AI tools will even provide little guidance about who developed the tool and what data it was trained on, regardless of what happens to the prompts and if they are collected and maintained in a secure way.</li>
<li>Promote regulation of AI tools by voting for standards where possible.</li>
</ul>
<div class="query">
<p><strong>Possible Generative AI Prompt:</strong>
Are there any methods that could be implemented to make this code more secure?</p>
</div>
</div>
<p><br></p>
<div class="fordev">
<p><strong>For decision makers about AI development:</strong></p>
<ul>
<li>Consult with an expert about data security if you want to design or use a AI tool that will regularly use private or propriety data.</li>
<li>Be clear with users about the limitations and security risks associated with tools that you develop.</li>
<li>Promote regulation of AI tools by voting for standards where possible.</li>
</ul>
<div class="query">
<p><strong>Possible Generative AI Prompt:</strong>
Are there any possible data security or privacy issues associated with the plan you proposed?</p>
</div>
</div>
</div>
</div>
<div id="climate-impact" class="section level2 hasAnchor">
<h2>Climate Impact<a href="societal-impact.html#climate-impact" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>AI can help humans to innovate ways to improve efficiency and to devise strategies to help mitigate climate issues (<span class="citation">Jansen et al. (<a href="#ref-jansen_climate_2023">2023</a>)</span>; <span class="citation">Cowls et al. (<a href="#ref-cowls_ai_2023">2023</a>)</span>). Importantly this needs to be done in a manner with social justice in mind, as often those that have the least resources deal with climate issues are also the most likely to be impacted (<span class="citation">Jansen et al. (<a href="#ref-jansen_climate_2023">2023</a>)</span>; <span class="citation">Bender et al. (<a href="#ref-bender_dangers_2021">2021</a>)</span>).</p>
<p>A few organizations are working on supporting the use of AI for climate crises mitigation uses such as:</p>
<ul>
<li>AI for the Plane: <a href="https://www.aifortheplanet.org/en" class="uri">https://www.aifortheplanet.org/en</a></li>
<li>Climate Change AI (CCAI): <a href="https://www.climatechange.ai/about" class="uri">https://www.climatechange.ai/about</a></li>
</ul>
<p>However, AI also poses a number of climate risks (<span class="citation">Bender et al. (<a href="#ref-bender_dangers_2021">2021</a>)</span>; <span class="citation">Hulick (<a href="#ref-hulick_training_2021">2021</a>)</span>; <span class="citation">Jansen et al. (<a href="#ref-jansen_climate_2023">2023</a>)</span>; <span class="citation">Cowls et al. (<a href="#ref-cowls_ai_2023">2023</a>)</span>) .</p>
<ol style="list-style-type: decimal">
<li>The data storage and computing resources needed for the development of AI tools could exacerbate climate challenges (<span class="citation">Bender et al. (<a href="#ref-bender_dangers_2021">2021</a>)</span>)</li>
<li>If not designed carefully, AI could also spread false solutions for climate crises or promote inefficient practices (<span class="citation">Jansen et al. (<a href="#ref-jansen_climate_2023">2023</a>)</span>).</li>
<li>Differences in access to AI technologies may exacerbate social inequities related to climate (<span class="citation">Hulick (<a href="#ref-hulick_training_2021">2021</a>)</span>)</li>
</ol>
<p><img src="resources/images/02b-Avoiding_Harm-concepts_files/figure-html/1L6-8DWn028c1o0p9gwXmz90BRcy_PjPqb683nbk1gHQ_g2aaead717c1_8_16.png" alt="A cartoon of robots camping." width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="tips-for-reducing-climate-impact" class="section level2 hasAnchor">
<h2>Tips for reducing climate impact<a href="societal-impact.html#tips-for-reducing-climate-impact" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="foruse">
<p><strong>For decision makers about AI use:</strong></p>
<ul>
<li>Where possible use tools that are transparent about resource usage and that identify how they have attempted to improve efficiency</li>
</ul>
</div>
<p><br></p>
<div class="fordev">
<p><strong>For decision makers about AI development:</strong></p>
<ul>
<li>Modify existing models as opposed to unnecessarily creating new models from scratch where possible.</li>
<li>Avoid using models with datasets that are unnecessarily large (<span class="citation">Bender et al. (<a href="#ref-bender_dangers_2021">2021</a>)</span>)</li>
<li>Solutions such as <a href="https://research.ibm.com/blog/what-is-federated-learning">federated learning</a>, where AI models are iteratively trained in multiple locations using data at those locations, instead of collectively sharing the data to create more massive datasets can help <a href="https://www.cam.ac.uk/research/news/can-federated-learning-save-the-world.">reduce</a> the required resources and also help preserve data privacy and security.</li>
<li>Use <a href="https://upcommons.upc.edu/handle/2117/393798">emerging tools and guidelines</a> to estimate and monitor the resource usage involved in training models (<span class="citation">Castaño Fernández (<a href="#ref-castano_fernandez_greenability_2023">2023</a>)</span>).</li>
<li>Be transparent about resources used to train models (<span class="citation">Castaño Fernández (<a href="#ref-castano_fernandez_greenability_2023">2023</a>)</span>).</li>
<li>Utilize data storage and computing options that are designed to be more environmentally conscious options, such as solar or wind power generated electricity.</li>
</ul>
</div>
</div>
<div id="transparency" class="section level2 hasAnchor">
<h2>Transparency<a href="societal-impact.html#transparency" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the United States Blueprint for the AI Bill of Rights, it states:</p>
<blockquote>
<p>You should know that an automated system is being used and understand how and why it contributes to outcomes that impact you.</p>
</blockquote>
<p>This transparency is important for people to understand how decisions are made using AI, which can be especially vital to allow people to contest decisions.</p>
<p>It also better helps us to understand what AI systems may need to be fixed or adapted if there are issues.</p>
<p><img src="resources/images/02b-Avoiding_Harm-concepts_files/figure-html/1L6-8DWn028c1o0p9gwXmz90BRcy_PjPqb683nbk1gHQ_g2aaead717c1_8_11.png" alt="An image of glass robots" width="100%" style="display: block; margin: auto;" /></p>
<div id="tips-for-being-transparent" class="section level3 hasAnchor">
<h3>Tips for being transparent<a href="societal-impact.html#tips-for-being-transparent" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="foruse">
<p><strong>For decision makers about AI use:</strong></p>
<ul>
<li>Where possible include the AI tool and version that you may be using and why so people can trace back where decisions or content came from</li>
<li>Use tools that are transparent about what data was used where possible</li>
</ul>
</div>
<p><br></p>
<div class="fordev">
<p><strong>For decision makers about AI development:</strong></p>
<ul>
<li>Providing information about what training data was or methods used to develop new AI models can help people to better understand why it is working in a particular</li>
</ul>
</div>
</div>
</div>
<div id="summary-3" class="section level2 hasAnchor">
<h2>Summary<a href="societal-impact.html#summary-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here is a summary of all the tips we suggested:</p>
<ul>
<li>Be mindful of how content created with AI or AI tools may be used for unintended purposes.</li>
<li>Be aware that humans are still better at generalizing concepts to other contexts (<span class="citation">Sinz et al. (<a href="#ref-sinz_engineering_2019">2019</a>)</span>).</li>
<li>Always have expert humans review content created by AI and value human contributions and thoughts.</li>
<li>Carefully consider if an AI solution is appropriate for your context.</li>
<li>Be aware that AI systems are biased and their responses are likely biased. Any content generated by an AI system should be evaluated for potential bias.</li>
<li>Be aware that AI systems may behave in unexpected ways. Implement new AI solutions slowly to account for the unexpected. Test those systems and try to better understand how they work in different contexts.</li>
<li>Be aware of the security and privacy concerns for AI, be sure to use the right tool for the job and train those at your institute appropriately.</li>
<li>Consider the climate impact of your AI usage and proceed in a manner makes efficient use of resources.</li>
<li>Be transparent about your use of AI.</li>
</ul>
<p>Overall, we hope that awareness of these concerns and the tips we shared will help us all use AI tools more responsibly. We recognize however, that as this is emerging technology and more ethical issues will emerge as we continue to use these tools in new ways. Staying up-to-date on the current ethical considerations will also help us all continue to use AI responsibly.</p>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bansal_ubers_2022" class="csl-entry">
Bansal, Varsha. 2022. <span>“Uber’s Facial Recognition Is Locking <span>Indian</span> Drivers Out of Their Accounts.”</span> <em>MIT Technology Review</em>. <a href="https://www.technologyreview.com/2022/12/06/1064287/ubers-facial-recognition-is-locking-indian-drivers-out-of-their-accounts/">https://www.technologyreview.com/2022/12/06/1064287/ubers-facial-recognition-is-locking-indian-drivers-out-of-their-accounts/</a>.
</div>
<div id="ref-belenguer_ai_2022" class="csl-entry">
Belenguer, Lorenzo. 2022. <span>“<span>AI</span> Bias: Exploring Discriminatory Algorithmic Decision-Making Models and the Application of Possible Machine-Centric Solutions Adapted from the Pharmaceutical Industry.”</span> <em>Ai and Ethics</em> 2 (4): 771–87. <a href="https://doi.org/10.1007/s43681-022-00138-8">https://doi.org/10.1007/s43681-022-00138-8</a>.
</div>
<div id="ref-bellaiche_humans_2023" class="csl-entry">
Bellaiche, Lucas, Rohin Shahi, Martin Harry Turpin, Anya Ragnhildstveit, Shawn Sprockett, Nathaniel Barr, Alexander Christensen, and Paul Seli. 2023. <span>“Humans Versus <span>AI</span>: Whether and Why We Prefer Human-Created Compared to <span>AI</span>-Created Artwork.”</span> <em>Cognitive Research: Principles and Implications</em> 8 (1): 42. <a href="https://doi.org/10.1186/s41235-023-00499-6">https://doi.org/10.1186/s41235-023-00499-6</a>.
</div>
<div id="ref-bender_dangers_2021" class="csl-entry">
Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. <span>“On the <span>Dangers</span> of <span>Stochastic</span> <span>Parrots</span>: <span>Can</span> <span>Language</span> <span>Models</span> <span>Be</span> <span>Too</span> <span>Big</span>?”</span> In <em>Proceedings of the 2021 <span>ACM</span> <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 610–23. <span>FAccT</span> ’21. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3442188.3445922">https://doi.org/10.1145/3442188.3445922</a>.
</div>
<div id="ref-castano_fernandez_greenability_2023" class="csl-entry">
Castaño Fernández, Joel. 2023. <span>“A Greenability Evaluation Sheet for <span>AI</span>-Based Systems.”</span> Bachelor thesis, Universitat Politècnica de Catalunya. <a href="https://upcommons.upc.edu/handle/2117/393798">https://upcommons.upc.edu/handle/2117/393798</a>.
</div>
<div id="ref-cowls_ai_2023" class="csl-entry">
Cowls, Josh, Andreas Tsamados, Mariarosaria Taddeo, and Luciano Floridi. 2023. <span>“The <span>AI</span> Gambit: Leveraging Artificial Intelligence to Combat Climate Change—Opportunities, Challenges, and Recommendations.”</span> <em>AI &amp; SOCIETY</em> 38 (1): 283–307. <a href="https://doi.org/10.1007/s00146-021-01294-x">https://doi.org/10.1007/s00146-021-01294-x</a>.
</div>
<div id="ref-gichoya_ai_2022" class="csl-entry">
Gichoya, Judy Wawira, Imon Banerjee, Ananth Reddy Bhimireddy, John L. Burns, Leo Anthony Celi, Li-Ching Chen, Ramon Correa, et al. 2022. <span>“<span>AI</span> Recognition of Patient Race in Medical Imaging: A Modelling Study.”</span> <em>The Lancet Digital Health</em> 4 (6): e406–14. <a href="https://doi.org/10.1016/S2589-7500(22)00063-2">https://doi.org/10.1016/S2589-7500(22)00063-2</a>.
</div>
<div id="ref-granulo_preference_2021" class="csl-entry">
Granulo, Armin, Christoph Fuchs, and Stefano Puntoni. 2021. <span>“Preference for <span>Human</span> (Vs. <span>Robotic</span>) <span>Labor</span> Is <span>Stronger</span> in <span>Symbolic</span> <span>Consumption</span> <span>Contexts</span>.”</span> <em>Journal of Consumer Psychology</em> 31 (1): 72–80. <a href="https://doi.org/10.1002/jcpy.1181">https://doi.org/10.1002/jcpy.1181</a>.
</div>
<div id="ref-AI_paternalism" class="csl-entry">
Hamzelou, Jessica. n.d. <span>“Artificial Intelligence Is Infiltrating Health Care. <span>We</span> Shouldn’t Let It Make All the Decisions.”</span> <em>MIT Technology Review</em>. Accessed May 8, 2023. <a href="https://www.technologyreview.com/2023/04/21/1071921/ai-is-infiltrating-health-care-we-shouldnt-let-it-make-decisions/">https://www.technologyreview.com/2023/04/21/1071921/ai-is-infiltrating-health-care-we-shouldnt-let-it-make-decisions/</a>.
</div>
<div id="ref-hulick_training_2021" class="csl-entry">
Hulick, Kathryn. 2021. <span>“Training <span>AI</span> to Be Really Smart Poses Risks to Climate.”</span> <a href="https://www.snexplores.org/article/training-ai-energy-emissions-climate-risk">https://www.snexplores.org/article/training-ai-energy-emissions-climate-risk</a>.
</div>
<div id="ref-jansen_climate_2023" class="csl-entry">
Jansen, Fieke, Merve Gulmez, Becky Kazansky, Narmine Abou Bakari, Claire Fernandez, Harriet Kingaby, and Jan Tobias Mühlberg. 2023. <span>“The <span>Climate</span> <span>Crisis</span> Is a <span>Digital</span> <span>Rights</span> <span>Crisis</span>: <span>Exploring</span> the <span>Civil</span>-<span>Society</span> <span>Framing</span> of <span>Two</span> <span>Intersecting</span> <span>Disasters</span>.”</span> In <em>Ninth <span>Computing</span> Within <span>Limits</span> 2023</em>. Virtual: LIMITS. <a href="https://doi.org/10.21428/bf6fb269.b4704652">https://doi.org/10.21428/bf6fb269.b4704652</a>.
</div>
<div id="ref-latar_robot_2015" class="csl-entry">
Latar, Noam. 2015. <span>“The <span>Robot</span> <span>Journalist</span> in the <span>Age</span> of <span>Social</span> <span>Physics</span>: <span>The</span> <span>End</span> of <span>Human</span> <span>Journalism</span>?”</span> In, 65–80. <a href="https://doi.org/10.1007/978-3-319-09009-2_6">https://doi.org/10.1007/978-3-319-09009-2_6</a>.
</div>
<div id="ref-nigro_ai_nodate" class="csl-entry">
Nigro, Pam. 2023. <span>“<span>AI</span> Security Risks: <span>Separating</span> Hype from Reality <span></span> <span>Security</span> <span>Magazine</span>.”</span> <a href="https://www.securitymagazine.com/articles/100219-ai-security-risks-separating-hype-from-reality">https://www.securitymagazine.com/articles/100219-ai-security-risks-separating-hype-from-reality</a>.
</div>
<div id="ref-paul_safeguards_2020" class="csl-entry">
Paul, Amy K, and Merrick Schaefer. 2020. <span>“Safeguards for the Use of Artificial Intelligence and Machine Learning in Global Health.”</span> <em>Bulletin of the World Health Organization</em> 98 (4): 282–84. <a href="https://doi.org/10.2471/BLT.19.237099">https://doi.org/10.2471/BLT.19.237099</a>.
</div>
<div id="ref-pearce_beware_2021" class="csl-entry">
Pearce, Guy. 2021. <span>“Beware the <span>Privacy</span> <span>Violations</span> in <span>Artificial</span> <span>Intelligence</span> <span>Applications</span>.”</span> <em>ISACA</em>. <a href="https://www.isaca.org/resources/news-and-trends/isaca-now-blog/2021/beware-the-privacy-violations-in-artificial-intelligence-applications">https://www.isaca.org/resources/news-and-trends/isaca-now-blog/2021/beware-the-privacy-violations-in-artificial-intelligence-applications</a>.
</div>
<div id="ref-pethig_biased_2023" class="csl-entry">
Pethig, Florian, and Julia Kroenung. 2023. <span>“Biased <span>Humans</span>, (<span>Un</span>)<span>Biased</span> <span>Algorithms</span>?”</span> <em>Journal of Business Ethics</em> 183 (3): 637–52. <a href="https://doi.org/10.1007/s10551-022-05071-8">https://doi.org/10.1007/s10551-022-05071-8</a>.
</div>
<div id="ref-selenko_artificial_2022" class="csl-entry">
Selenko, Eva, Sarah Bankins, Mindy Shoss, Joel Warburton, and Simon Lloyd D. Restubog. 2022. <span>“Artificial <span>Intelligence</span> and the <span>Future</span> of <span>Work</span>: <span>A</span> <span>Functional</span>-<span>Identity</span> <span>Perspective</span>.”</span> <em>Current Directions in Psychological Science</em> 31 (3): 272–79. <a href="https://doi.org/10.1177/09637214221091823">https://doi.org/10.1177/09637214221091823</a>.
</div>
<div id="ref-sinz_engineering_2019" class="csl-entry">
Sinz, Fabian H., Xaq Pitkow, Jacob Reimer, Matthias Bethge, and Andreas S. Tolias. 2019. <span>“Engineering a <span>Less</span> <span>Artificial</span> <span>Intelligence</span>.”</span> <em>Neuron</em> 103 (6): 967–79. <a href="https://doi.org/10.1016/j.neuron.2019.08.034">https://doi.org/10.1016/j.neuron.2019.08.034</a>.
</div>
</div>
<hr>
<center> 
  <div class="footer">
      All illustrations <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY. </a>
      <br>
      All other materials <a href= "https://creativecommons.org/licenses/by/4.0/"> CC-BY </a> unless noted otherwise.
      <a href="https://hutchdatascience.org/" target="_blank"><img src="https://hutchdatascience.org/images/crazy-idea-wide.png" style="width: 80%; padding-left: 15px; padding-top: 8px;"</a>
  </div>
</center>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-avoiding-ai-harm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="algorithm-considerations.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
